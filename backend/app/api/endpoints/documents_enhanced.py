"""
å¢žå¼·ç‰ˆå…¬æ–‡ç®¡ç† API ç«¯é»ž - POST-only è³‡å®‰æ©Ÿåˆ¶ï¼Œçµ±ä¸€å›žæ‡‰æ ¼å¼
v2.3 - æ¬Šé™ç®¡æŽ§å‡ç´š (2026-01-10)

è®Šæ›´ç´€éŒ„:
- v2.3: æ–°å¢žè¡Œç´šåˆ¥æ¬Šé™éŽæ¿¾ï¼ˆéžç®¡ç†å“¡åªèƒ½æŸ¥çœ‹é—œè¯å°ˆæ¡ˆçš„å…¬æ–‡ï¼‰
- v2.2: ä½¿ç”¨ AuditService çµ±ä¸€ç®¡ç†å¯©è¨ˆæ—¥èªŒï¼ˆç¨ç«‹ sessionï¼Œä¸æœƒæ±¡æŸ“ä¸»äº¤æ˜“ï¼‰
- v2.2: ä½¿ç”¨ NotificationService.safe_* æ–¹æ³•ï¼ˆç¨ç«‹ sessionï¼‰
- v2.2: ç§»é™¤å°èˆŠ log_document_change å‡½æ•¸çš„ä¾è³´
"""
import io
import os
import csv
import shutil
import logging
from typing import Optional, List
from datetime import date as date_type
from fastapi import APIRouter, Query, Depends, Body, UploadFile, File
from fastapi.responses import StreamingResponse
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import text, select, or_, and_, func
from sqlalchemy.orm import selectinload
from pydantic import BaseModel, Field, field_validator

logger = logging.getLogger(__name__)


def parse_date_string(date_str: Optional[str]) -> Optional[date_type]:
    """å°‡æ—¥æœŸå­—ä¸²è½‰æ›ç‚º Python date ç‰©ä»¶"""
    if not date_str:
        return None
    try:
        # æ”¯æ´ YYYY-MM-DD æ ¼å¼
        parts = date_str.split('-')
        if len(parts) == 3:
            return date_type(int(parts[0]), int(parts[1]), int(parts[2]))
        return None
    except (ValueError, IndexError):
        logger.warning(f"ç„¡æ³•è§£æžæ—¥æœŸå­—ä¸²: {date_str}")
        return None

from app.db.database import get_async_db
from app.extended.models import OfficialDocument, ContractProject, GovernmentAgency, DocumentAttachment
from app.services.document_service import DocumentService
from app.schemas.document import (
    DocumentFilter, DocumentListQuery, DocumentListResponse, DocumentResponse, StaffInfo,
    DocumentCreateRequest, DocumentUpdateRequest, VALID_DOC_TYPES
)
from app.extended.models import User, project_user_assignment
from app.schemas.common import (
    PaginationMeta,
    DeleteResponse,
    SuccessResponse,
    SortOrder,
)
# çµ±ä¸€å¾ž schemas åŒ¯å…¥æŸ¥è©¢ç›¸é—œåž‹åˆ¥
from app.schemas.document_query import (
    DropdownQuery,
    AgencyDropdownQuery,
    OptimizedSearchRequest,
    SearchSuggestionRequest,
    AuditLogQuery,
    AuditLogItem,
    AuditLogResponse,
    ProjectDocumentsQuery,
    DocumentExportQuery,
    ExcelExportRequest,
)
from app.core.exceptions import NotFoundException, ForbiddenException
from app.core.audit_logger import DocumentUpdateGuard
from app.services.notification_service import NotificationService, CRITICAL_FIELDS
from app.core.dependencies import require_auth, require_permission

# ä½¿ç”¨è€…èªè­‰ï¼ˆv2.3 å‡ç´šç‚ºå¿…è¦ï¼‰
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
security = HTTPBearer(auto_error=False)

# çµ±ä¸€ä½¿ç”¨ require_auth é€²è¡Œèªè­‰
from app.api.endpoints.auth import get_current_user

async def get_optional_user(
    credentials: Optional[HTTPAuthorizationCredentials] = Depends(security),
    db: AsyncSession = Depends(get_async_db)
) -> Optional[User]:
    """å–å¾—ç•¶å‰ä½¿ç”¨è€…ï¼ˆå¯é¸ï¼Œä¸å¼·åˆ¶èªè­‰ï¼‰- åƒ…ç”¨æ–¼å‘å¾Œç›¸å®¹"""
    try:
        if not credentials:
            return None
        return await get_current_user(credentials, db)
    except Exception:
        return None

router = APIRouter()


# ============================================================================
# å…¬æ–‡åˆ—è¡¨ APIï¼ˆPOST-only è³‡å®‰æ©Ÿåˆ¶ï¼‰
# ============================================================================

@router.post(
    "/list",
    response_model=DocumentListResponse,
    summary="æŸ¥è©¢å…¬æ–‡åˆ—è¡¨",
    description="ä½¿ç”¨çµ±ä¸€åˆ†é æ ¼å¼æŸ¥è©¢å…¬æ–‡åˆ—è¡¨ï¼ˆPOST-only è³‡å®‰æ©Ÿåˆ¶ï¼Œå«è¡Œç´šåˆ¥æ¬Šé™éŽæ¿¾ï¼‰"
)
async def list_documents(
    query: DocumentListQuery = Body(default=DocumentListQuery()),
    db: AsyncSession = Depends(get_async_db),
    current_user: User = Depends(require_auth())
):
    """
    æŸ¥è©¢å…¬æ–‡åˆ—è¡¨ï¼ˆPOST-only è³‡å®‰æ©Ÿåˆ¶ï¼‰

    ðŸ”’ æ¬Šé™è¦å‰‡ï¼š
    - éœ€è¦ç™»å…¥èªè­‰
    - superuser/admin: å¯æŸ¥çœ‹æ‰€æœ‰å…¬æ–‡
    - ä¸€èˆ¬ä½¿ç”¨è€…: åªèƒ½æŸ¥çœ‹é—œè¯å°ˆæ¡ˆçš„å…¬æ–‡ï¼Œæˆ–ç„¡å°ˆæ¡ˆé—œè¯çš„å…¬æ–‡

    å›žæ‡‰æ ¼å¼ï¼š
    ```json
    {
        "success": true,
        "items": [...],
        "pagination": {
            "total": 100,
            "page": 1,
            "limit": 20,
            "total_pages": 5,
            "has_next": true,
            "has_prev": false
        }
    }
    ```
    """
    try:
        # è©³ç´°è¨˜éŒ„æ‰€æœ‰æŸ¥è©¢åƒæ•¸
        logger.info(f"[API] å…¬æ–‡æŸ¥è©¢è«‹æ±‚: keyword={query.keyword}, doc_number={query.doc_number}, "
                   f"doc_type={query.doc_type}, year={query.year}, "
                   f"sender={query.sender}, receiver={query.receiver}, "
                   f"delivery_method={query.delivery_method}, "
                   f"doc_date_from={query.doc_date_from}, doc_date_to={query.doc_date_to}, "
                   f"contract_case={query.contract_case}, category={query.category}")

        service = DocumentService(db)

        # æ§‹å»ºç¯©é¸æ¢ä»¶
        filters = DocumentFilter(
            keyword=query.keyword,
            doc_number=query.doc_number,  # å…¬æ–‡å­—è™Ÿå°ˆç”¨ç¯©é¸
            doc_type=query.doc_type,
            year=query.year,
            status=query.status,
            sender=query.sender,
            receiver=query.receiver,
            date_from=query.doc_date_from,
            date_to=query.doc_date_to,
            delivery_method=query.delivery_method,
            contract_case=query.contract_case,  # ç›´æŽ¥è¨­å®šï¼Œä¸ç”¨ setattr
            sort_by=query.sort_by,
            sort_order=query.sort_order.value if query.sort_order else "desc"
        )

        # åŠ å…¥æ”¶ç™¼æ–‡åˆ†é¡žç¯©é¸ (å‰ç«¯ç”¨ send/receiveï¼Œè³‡æ–™åº«ç”¨ ç™¼æ–‡/æ”¶æ–‡)
        if query.category:
            category_mapping = {'send': 'ç™¼æ–‡', 'receive': 'æ”¶æ–‡'}
            db_category = category_mapping.get(query.category, query.category)
            setattr(filters, 'category', db_category)

        # è¨ˆç®— skip
        skip = (query.page - 1) * query.limit

        # å‚³éž current_user é€²è¡Œè¡Œç´šåˆ¥æ¬Šé™éŽæ¿¾
        result = await service.get_documents(
            skip=skip,
            limit=query.limit,
            filters=filters,
            current_user=current_user
        )

        # è½‰æ›ç‚ºçµ±ä¸€å›žæ‡‰æ ¼å¼
        items = result.get("items", [])
        total = result.get("total", 0)

        # æ”¶é›†æ‰€æœ‰ project_id ä»¥æ‰¹æ¬¡æŸ¥è©¢
        project_ids = list(set(doc.contract_project_id for doc in items if doc.contract_project_id))

        # æ‰¹æ¬¡æŸ¥è©¢æ‰¿æ”¬æ¡ˆä»¶è³‡è¨Š
        project_map = {}
        staff_map = {}
        if project_ids:
            # æŸ¥è©¢æ¡ˆä»¶åç¨±
            project_query = select(ContractProject.id, ContractProject.project_name).where(
                ContractProject.id.in_(project_ids)
            )
            project_result = await db.execute(project_query)
            for row in project_result:
                project_map[row.id] = row.project_name

            # æŸ¥è©¢æ¥­å‹™åŒä»
            staff_query = select(
                project_user_assignment.c.project_id,
                project_user_assignment.c.role,
                User.id.label('user_id'),
                User.full_name
            ).select_from(
                project_user_assignment.join(User, project_user_assignment.c.user_id == User.id)
            ).where(project_user_assignment.c.project_id.in_(project_ids))

            staff_result = await db.execute(staff_query)
            for row in staff_result:
                if row.project_id not in staff_map:
                    staff_map[row.project_id] = []
                staff_map[row.project_id].append(StaffInfo(
                    user_id=row.user_id,
                    name=row.full_name or 'æœªçŸ¥',
                    role=row.role or 'member'
                ))

        # æ‰¹æ¬¡æŸ¥è©¢é™„ä»¶æ•¸é‡ï¼ˆN+1 å„ªåŒ–ï¼‰
        attachment_count_map = {}
        doc_ids = [doc.id for doc in items]
        if doc_ids:
            attachment_query = select(
                DocumentAttachment.document_id,
                func.count(DocumentAttachment.id).label('count')
            ).where(
                DocumentAttachment.document_id.in_(doc_ids)
            ).group_by(DocumentAttachment.document_id)

            attachment_result = await db.execute(attachment_query)
            for row in attachment_result:
                attachment_count_map[row.document_id] = row.count

        # æ‰¹æ¬¡æŸ¥è©¢æ©Ÿé—œåç¨±ï¼ˆ2026-01-08 æ–°å¢žï¼Œæ”¯æ´å‰ç«¯é¡¯ç¤ºï¼‰
        agency_map = {}
        agency_ids = set()
        for doc in items:
            if doc.sender_agency_id:
                agency_ids.add(doc.sender_agency_id)
            if doc.receiver_agency_id:
                agency_ids.add(doc.receiver_agency_id)

        if agency_ids:
            agency_query = select(
                GovernmentAgency.id,
                GovernmentAgency.agency_name
            ).where(GovernmentAgency.id.in_(agency_ids))
            agency_result = await db.execute(agency_query)
            for row in agency_result:
                agency_map[row.id] = row.agency_name

        # è½‰æ›ç‚º DocumentResponse
        response_items = []
        for doc in items:
            try:
                doc_dict = {
                    **doc.__dict__,
                    'contract_project_name': project_map.get(doc.contract_project_id) if doc.contract_project_id else None,
                    'assigned_staff': staff_map.get(doc.contract_project_id, []) if doc.contract_project_id else [],
                    'attachment_count': attachment_count_map.get(doc.id, 0),
                    # æ©Ÿé—œåç¨±è™›æ“¬æ¬„ä½
                    'sender_agency_name': agency_map.get(doc.sender_agency_id) if doc.sender_agency_id else None,
                    'receiver_agency_name': agency_map.get(doc.receiver_agency_id) if doc.receiver_agency_id else None,
                }
                # ç§»é™¤ SQLAlchemy å…§éƒ¨å±¬æ€§
                doc_dict.pop('_sa_instance_state', None)
                response_items.append(DocumentResponse.model_validate(doc_dict))
            except Exception as e:
                logger.warning(f"è½‰æ›å…¬æ–‡è³‡æ–™å¤±æ•—: {e}")
                continue

        return DocumentListResponse(
            items=response_items,
            pagination=PaginationMeta.create(
                total=total,
                page=query.page,
                limit=query.limit
            )
        )

    except Exception as e:
        logger.error(f"å…¬æ–‡æŸ¥è©¢å¤±æ•—: {e}", exc_info=True)
        return DocumentListResponse(
            items=[],
            pagination=PaginationMeta.create(total=0, page=1, limit=query.limit)
        )


# ============================================================================
# ä¸‹æ‹‰é¸é … APIï¼ˆPOST-only è³‡å®‰æ©Ÿåˆ¶ï¼‰
# ============================================================================

@router.post(
    "/contract-projects-dropdown",
    summary="å–å¾—æ‰¿æ”¬æ¡ˆä»¶ä¸‹æ‹‰é¸é …"
)
async def get_contract_projects_dropdown(
    query: DropdownQuery = Body(default=DropdownQuery()),
    db: AsyncSession = Depends(get_async_db)
):
    """å–å¾—æ‰¿æ”¬æ¡ˆä»¶ä¸‹æ‹‰é¸é … - å¾ž contract_projects è¡¨æŸ¥è©¢"""
    try:
        db_query = select(
            ContractProject.id,
            ContractProject.project_name,
            ContractProject.year,
            ContractProject.category
        )

        if query.search:
            db_query = db_query.where(
                or_(
                    ContractProject.project_name.ilike(f"%{query.search}%"),
                    ContractProject.project_code.ilike(f"%{query.search}%"),
                    ContractProject.client_agency.ilike(f"%{query.search}%")
                )
            )

        db_query = db_query.order_by(
            ContractProject.year.desc(),
            ContractProject.project_name.asc()
        ).limit(query.limit)

        result = await db.execute(db_query)
        projects = result.all()

        options = []
        for project in projects:
            options.append({
                "value": project.project_name,
                "label": f"{project.project_name} ({project.year}å¹´)",
                "id": project.id,
                "year": project.year,
                "category": project.category
            })

        return {
            "success": True,
            "options": options,
            "total": len(options)
        }

    except Exception as e:
        logger.error(f"å–å¾—æ‰¿æ”¬æ¡ˆä»¶é¸é …å¤±æ•—: {e}", exc_info=True)
        return {"success": False, "options": [], "total": 0, "error": str(e)}


def _extract_agency_names_from_raw(raw_value: str) -> list:
    """
    å¾žè³‡æ–™åº«åŽŸå§‹å€¼ä¸­æå–ç´”æ©Ÿé—œåç¨±

    æ”¯æ´æ ¼å¼ï¼š
    - ç´”åç¨±: "æ¡ƒåœ’å¸‚æ”¿åºœ"
    - ä»£ç¢¼+åç¨±: "380110000G (æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€)"
    - å¤šæ©Ÿé—œ: "376480000A (å—æŠ•ç¸£æ”¿åºœ) | A01020100G (å…§æ”¿éƒ¨åœ‹åœŸç®¡ç†ç½²åŸŽé„‰ç™¼å±•åˆ†ç½²)"
    - æ›è¡Œæ ¼å¼: "380110000G\\n(æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€)"

    Returns:
        æå–å‡ºçš„ç´”æ©Ÿé—œåç¨±åˆ—è¡¨
    """
    import re

    if not raw_value:
        return []

    names = []

    # å…ˆæŒ‰ | åˆ†å‰²å¤šå€‹æ©Ÿé—œ
    parts = raw_value.split('|')

    for part in parts:
        part = part.strip()
        if not part:
            continue

        # è™•ç†æ›è¡Œæ ¼å¼: "380110000G\n(æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€)"
        part = part.replace('\n', ' ').replace('\r', ' ')

        # å˜—è©¦æå–æ‹¬è™Ÿå…§çš„åç¨±: "380110000G (æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€)" -> "æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€"
        match = re.search(r'\(([^)]+)\)', part)
        if match:
            names.append(match.group(1).strip())
        else:
            # å˜—è©¦ç§»é™¤ä»£ç¢¼å‰ç¶´: "380110000G æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€" -> "æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€"
            # ä»£ç¢¼æ ¼å¼é€šå¸¸æ˜¯ å­—æ¯+æ•¸å­— çµ„åˆ
            cleaned = re.sub(r'^[A-Z0-9]+\s*', '', part, flags=re.IGNORECASE)
            if cleaned:
                names.append(cleaned.strip())
            else:
                # å¦‚æžœå…¨éƒ½è¢«ç§»é™¤äº†ï¼Œå°±ç”¨åŽŸå€¼ï¼ˆå¯èƒ½æœ¬èº«å°±æ˜¯ç´”åç¨±ï¼‰
                names.append(part)

    return names


@router.post(
    "/agencies-dropdown",
    summary="å–å¾—æ”¿åºœæ©Ÿé—œä¸‹æ‹‰é¸é …"
)
async def get_agencies_dropdown(
    query: AgencyDropdownQuery = Body(default=AgencyDropdownQuery()),
    db: AsyncSession = Depends(get_async_db)
):
    """
    å–å¾—æ”¿åºœæ©Ÿé—œä¸‹æ‹‰é¸é …

    å„ªåŒ–ç‰ˆï¼šå¾ž government_agencies è¡¨å–å¾—æ¨™æº–åŒ–æ©Ÿé—œåç¨±ï¼Œ
    èˆ‡ http://localhost:3000/agencies é é¢é¡¯ç¤ºä¸€è‡´ã€‚
    """
    try:
        # å¾ž government_agencies è¡¨å–å¾—æ¨™æº–åŒ–æ©Ÿé—œåç¨±
        sql_query = """
        SELECT id, agency_name, agency_code, agency_short_name
        FROM government_agencies
        WHERE agency_name IS NOT NULL AND agency_name != ''
        """

        params = {}
        if query.search:
            sql_query += " AND (agency_name ILIKE :search OR agency_short_name ILIKE :search)"
            params["search"] = f"%{query.search}%"

        sql_query += " ORDER BY agency_name LIMIT :limit"
        params["limit"] = query.limit

        result = await db.execute(text(sql_query), params)
        agencies = result.fetchall()

        options = []
        for row in agencies:
            options.append({
                "value": row.agency_name,  # ä½¿ç”¨æ¨™æº–åŒ–åç¨±ä½œç‚ºå€¼
                "label": row.agency_name,  # é¡¯ç¤ºæ¨™æº–åŒ–åç¨±
                "id": row.id,
                "agency_code": row.agency_code or "",
                "agency_short_name": row.agency_short_name or ""
            })

        return {
            "success": True,
            "options": options,
            "total": len(options)
        }

    except Exception as e:
        logger.error(f"å–å¾—æ”¿åºœæ©Ÿé—œé¸é …å¤±æ•—: {e}", exc_info=True)
        return {"success": False, "options": [], "total": 0, "error": str(e)}


@router.post(
    "/years",
    summary="å–å¾—æ–‡æª”å¹´åº¦é¸é …"
)
async def get_document_years(
    db: AsyncSession = Depends(get_async_db)
):
    """å–å¾—æ–‡æª”å¹´åº¦é¸é …"""
    try:
        sql_query = """
        SELECT DISTINCT EXTRACT(YEAR FROM doc_date) as year
        FROM documents
        WHERE doc_date IS NOT NULL
        ORDER BY year DESC
        """

        result = await db.execute(text(sql_query))
        years = result.fetchall()

        year_list = [int(row.year) for row in years if row.year]

        return {
            "success": True,
            "years": year_list,
            "total": len(year_list)
        }

    except Exception as e:
        logger.error(f"å–å¾—å¹´åº¦é¸é …å¤±æ•—: {e}", exc_info=True)
        return {"success": False, "years": [], "total": 0}


@router.post(
    "/statistics",
    summary="å–å¾—å…¬æ–‡çµ±è¨ˆè³‡æ–™"
)
async def get_documents_statistics(
    db: AsyncSession = Depends(get_async_db)
):
    """å–å¾—å…¬æ–‡çµ±è¨ˆè³‡æ–™ (æ”¶ç™¼æ–‡åˆ†é¡žåŸºæ–¼ category æ¬„ä½)"""
    try:
        total_query = "SELECT COUNT(*) as count FROM documents"
        send_query = "SELECT COUNT(*) as count FROM documents WHERE category = 'ç™¼æ–‡'"
        receive_query = "SELECT COUNT(*) as count FROM documents WHERE category = 'æ”¶æ–‡'"
        current_year_query = "SELECT COUNT(*) as count FROM documents WHERE EXTRACT(YEAR FROM doc_date) = EXTRACT(YEAR FROM CURRENT_DATE)"

        # ç™¼æ–‡å½¢å¼çµ±è¨ˆ (åƒ…çµ±è¨ˆç™¼æ–‡é¡žåˆ¥)
        electronic_query = "SELECT COUNT(*) as count FROM documents WHERE category = 'ç™¼æ–‡' AND delivery_method = 'é›»å­äº¤æ›'"
        paper_query = "SELECT COUNT(*) as count FROM documents WHERE category = 'ç™¼æ–‡' AND delivery_method = 'ç´™æœ¬éƒµå¯„'"
        both_query = "SELECT COUNT(*) as count FROM documents WHERE category = 'ç™¼æ–‡' AND delivery_method = 'é›»å­+ç´™æœ¬'"

        # æœ¬å¹´åº¦ç™¼æ–‡æ•¸
        current_year_send_query = "SELECT COUNT(*) as count FROM documents WHERE category = 'ç™¼æ–‡' AND EXTRACT(YEAR FROM doc_date) = EXTRACT(YEAR FROM CURRENT_DATE)"

        total_result = await db.execute(text(total_query))
        send_result = await db.execute(text(send_query))
        receive_result = await db.execute(text(receive_query))
        current_year_result = await db.execute(text(current_year_query))

        # ç™¼æ–‡å½¢å¼çµ±è¨ˆ
        electronic_result = await db.execute(text(electronic_query))
        paper_result = await db.execute(text(paper_query))
        both_result = await db.execute(text(both_query))
        current_year_send_result = await db.execute(text(current_year_send_query))

        total = total_result.scalar() or 0
        send = send_result.scalar() or 0
        receive = receive_result.scalar() or 0

        return {
            "success": True,
            "total": total,
            "total_documents": total,
            "send": send,
            "send_count": send,
            "receive": receive,
            "receive_count": receive,
            "current_year_count": current_year_result.scalar() or 0,
            "current_year_send_count": current_year_send_result.scalar() or 0,
            "delivery_method_stats": {
                "electronic": electronic_result.scalar() or 0,
                "paper": paper_result.scalar() or 0,
                "both": both_result.scalar() or 0
            }
        }
    except Exception as e:
        logger.error(f"å–å¾—çµ±è¨ˆè³‡æ–™å¤±æ•—: {e}", exc_info=True)
        return {
            "success": False,
            "total": 0,
            "total_documents": 0,
            "send": 0,
            "send_count": 0,
            "receive": 0,
            "receive_count": 0,
            "current_year_count": 0,
            "current_year_send_count": 0,
            "delivery_method_stats": {
                "electronic": 0,
                "paper": 0,
                "both": 0
            }
        }


@router.post(
    "/filtered-statistics",
    summary="å–å¾—ç¯©é¸å¾Œçš„å…¬æ–‡çµ±è¨ˆè³‡æ–™"
)
async def get_filtered_statistics(
    query: DocumentListQuery = Body(default=DocumentListQuery()),
    db: AsyncSession = Depends(get_async_db)
):
    """
    æ ¹æ“šç¯©é¸æ¢ä»¶å–å¾—å‹•æ…‹çµ±è¨ˆè³‡æ–™

    å›žå‚³åŸºæ–¼ç•¶å‰ç¯©é¸æ¢ä»¶çš„ï¼š
    - total: ç¬¦åˆæ¢ä»¶çš„ç¸½æ•¸
    - send_count: ç¬¦åˆæ¢ä»¶çš„ç™¼æ–‡æ•¸
    - receive_count: ç¬¦åˆæ¢ä»¶çš„æ”¶æ–‡æ•¸

    ç”¨æ–¼å‰ç«¯ Tab æ¨™ç±¤çš„å‹•æ…‹æ•¸å­—é¡¯ç¤º
    """
    try:
        # æ§‹å»ºåŸºæœ¬ WHERE æ¢ä»¶ï¼ˆä¸å« categoryï¼‰
        conditions = []
        params = {}

        # å…¬æ–‡å­—è™Ÿå°ˆç”¨ç¯©é¸ï¼ˆåƒ…æœå°‹ doc_number æ¬„ä½ï¼‰
        if query.doc_number:
            conditions.append("doc_number ILIKE :doc_number")
            params["doc_number"] = f"%{query.doc_number}%"

        # é—œéµå­—æœå°‹ï¼ˆä¸»æ—¨ã€èªªæ˜Žã€å‚™è¨» - ä¸å« doc_numberï¼‰
        if query.keyword:
            conditions.append("""
                (subject ILIKE :keyword
                 OR content ILIKE :keyword OR notes ILIKE :keyword)
            """)
            params["keyword"] = f"%{query.keyword}%"

        if query.doc_type:
            conditions.append("doc_type = :doc_type")
            params["doc_type"] = query.doc_type

        if query.year:
            conditions.append("EXTRACT(YEAR FROM doc_date) = :year")
            params["year"] = query.year

        if query.sender:
            conditions.append("sender ILIKE :sender")
            params["sender"] = f"%{query.sender}%"

        if query.receiver:
            conditions.append("receiver ILIKE :receiver")
            params["receiver"] = f"%{query.receiver}%"

        if query.delivery_method:
            conditions.append("delivery_method = :delivery_method")
            params["delivery_method"] = query.delivery_method

        if query.doc_date_from:
            conditions.append("doc_date >= :doc_date_from")
            params["doc_date_from"] = query.doc_date_from

        if query.doc_date_to:
            conditions.append("doc_date <= :doc_date_to")
            params["doc_date_to"] = query.doc_date_to

        if query.contract_case:
            # éœ€è¦ JOIN contract_projects è¡¨
            conditions.append("""
                contract_project_id IN (
                    SELECT id FROM contract_projects
                    WHERE project_name ILIKE :contract_case OR project_code ILIKE :contract_case
                )
            """)
            params["contract_case"] = f"%{query.contract_case}%"

        # çµ„åˆ WHERE å­å¥
        where_clause = " AND ".join(conditions) if conditions else "1=1"

        # ç¸½æ•¸æŸ¥è©¢
        total_query = f"SELECT COUNT(*) FROM documents WHERE {where_clause}"
        total_result = await db.execute(text(total_query), params)
        total = total_result.scalar() or 0

        # ç™¼æ–‡æ•¸æŸ¥è©¢
        send_query = f"SELECT COUNT(*) FROM documents WHERE {where_clause} AND category = 'ç™¼æ–‡'"
        send_result = await db.execute(text(send_query), params)
        send_count = send_result.scalar() or 0

        # æ”¶æ–‡æ•¸æŸ¥è©¢
        receive_query = f"SELECT COUNT(*) FROM documents WHERE {where_clause} AND category = 'æ”¶æ–‡'"
        receive_result = await db.execute(text(receive_query), params)
        receive_count = receive_result.scalar() or 0

        logger.info(f"ç¯©é¸çµ±è¨ˆ: total={total}, send={send_count}, receive={receive_count}, filters={params}")

        return {
            "success": True,
            "total": total,
            "send_count": send_count,
            "receive_count": receive_count,
            "filters_applied": bool(conditions)
        }

    except Exception as e:
        logger.error(f"å–å¾—ç¯©é¸çµ±è¨ˆå¤±æ•—: {e}", exc_info=True)
        return {
            "success": False,
            "total": 0,
            "send_count": 0,
            "receive_count": 0,
            "filters_applied": False,
            "error": str(e)
        }


# ============================================================================
# å„ªåŒ–æœå°‹ API
# ============================================================================

@router.post(
    "/search/optimized",
    summary="å„ªåŒ–å…¨æ–‡æœå°‹",
    description="ä½¿ç”¨æ™ºèƒ½é—œéµå­—è™•ç†å’ŒçµæžœæŽ’åçš„å„ªåŒ–æœå°‹"
)
async def optimized_search(
    request: OptimizedSearchRequest,
    db: AsyncSession = Depends(get_async_db)
):
    """
    å„ªåŒ–å…¨æ–‡æœå°‹

    ç‰¹é»žï¼š
    - æ™ºèƒ½é—œéµå­—åˆ†è©žè™•ç†
    - æ”¯æ´å…¬æ–‡å­—è™Ÿæ ¼å¼è­˜åˆ¥
    - å¤šæ¬„ä½æ¬Šé‡æœå°‹
    - æœå°‹çµæžœå¿«å–
    """
    from app.services.search_optimizer import SearchOptimizer

    try:
        optimizer = SearchOptimizer(db)

        # æ§‹å»ºç¯©é¸æ¢ä»¶
        filters = {}
        if request.category:
            category_mapping = {'send': 'ç™¼æ–‡', 'receive': 'æ”¶æ–‡'}
            filters['category'] = category_mapping.get(request.category, request.category)
        if request.delivery_method:
            filters['delivery_method'] = request.delivery_method
        if request.year:
            filters['year'] = request.year

        # åŸ·è¡Œå„ªåŒ–æœå°‹
        skip = (request.page - 1) * request.limit
        result = await optimizer.search_with_ranking(
            keyword=request.keyword,
            filters=filters,
            skip=skip,
            limit=request.limit
        )

        # è½‰æ›çµæžœæ ¼å¼
        items = []
        for doc in result.get("items", []):
            items.append({
                "id": doc.id,
                "doc_number": doc.doc_number,
                "doc_type": doc.doc_type,
                "subject": doc.subject,
                "sender": doc.sender,
                "receiver": doc.receiver,
                "doc_date": str(doc.doc_date) if doc.doc_date else None,
                "category": doc.category,
                "delivery_method": doc.delivery_method,
                "status": doc.status,
            })

        total = result.get("total", 0)

        return {
            "success": True,
            "items": items,
            "pagination": {
                "total": total,
                "page": request.page,
                "limit": request.limit,
                "total_pages": (total + request.limit - 1) // request.limit if request.limit > 0 else 0,
                "has_next": request.page * request.limit < total,
                "has_prev": request.page > 1
            },
            "search_info": {
                "tokens": result.get("tokens", []),
                "normalized_keyword": result.get("normalized_keyword", request.keyword)
            }
        }

    except Exception as e:
        logger.error(f"å„ªåŒ–æœå°‹å¤±æ•—: {e}", exc_info=True)
        return {
            "success": False,
            "items": [],
            "pagination": {"total": 0, "page": 1, "limit": request.limit},
            "error": str(e)
        }


@router.post(
    "/search/suggestions",
    summary="å–å¾—æœå°‹å»ºè­°",
    description="æ ¹æ“šè¼¸å…¥å‰ç¶´æä¾›è‡ªå‹•å®Œæˆå»ºè­°"
)
async def get_search_suggestions(
    request: SearchSuggestionRequest,
    db: AsyncSession = Depends(get_async_db)
):
    """
    å–å¾—æœå°‹å»ºè­°ï¼ˆè‡ªå‹•å®Œæˆï¼‰

    æ ¹æ“šç”¨æˆ¶è¼¸å…¥æä¾›ï¼š
    - ä¸»æ—¨åŒ¹é…å»ºè­°
    - æ–‡è™ŸåŒ¹é…å»ºè­°
    """
    from app.services.search_optimizer import SearchOptimizer

    try:
        optimizer = SearchOptimizer(db)
        suggestions = await optimizer.get_search_suggestions(
            prefix=request.prefix,
            limit=request.limit
        )

        return {
            "success": True,
            "suggestions": suggestions,
            "count": len(suggestions)
        }

    except Exception as e:
        logger.error(f"å–å¾—æœå°‹å»ºè­°å¤±æ•—: {e}", exc_info=True)
        return {
            "success": False,
            "suggestions": [],
            "error": str(e)
        }


@router.post(
    "/search/popular",
    summary="å–å¾—ç†±é–€æœå°‹è©ž",
    description="å–å¾—æœ€è¿‘çš„ç†±é–€æœå°‹é—œéµè©ž"
)
async def get_popular_searches(
    limit: int = Query(default=10, ge=1, le=20, description="æ•¸é‡ä¸Šé™"),
    db: AsyncSession = Depends(get_async_db)
):
    """å–å¾—ç†±é–€æœå°‹è©ž"""
    from app.services.search_optimizer import SearchOptimizer

    try:
        optimizer = SearchOptimizer(db)
        popular = await optimizer.get_popular_searches(limit=limit)

        return {
            "success": True,
            "popular_searches": popular,
            "count": len(popular)
        }

    except Exception as e:
        logger.error(f"å–å¾—ç†±é–€æœå°‹å¤±æ•—: {e}", exc_info=True)
        return {
            "success": False,
            "popular_searches": [],
            "error": str(e)
        }


# ============================================================================
# å…¬æ–‡ CRUD APIï¼ˆPOST-only è³‡å®‰æ©Ÿåˆ¶ï¼‰
# ============================================================================

# æ³¨æ„ï¼šDocumentCreateRequest, DocumentUpdateRequest, VALID_DOC_TYPES
# å·²çµ±ä¸€å®šç¾©æ–¼ app/schemas/document.pyï¼Œæ­¤è™•é€éŽ import ä½¿ç”¨


@router.post(
    "/{document_id}/detail",
    response_model=DocumentResponse,
    summary="å–å¾—å…¬æ–‡è©³æƒ…"
)
async def get_document_detail(
    document_id: int,
    db: AsyncSession = Depends(get_async_db),
    current_user: User = Depends(require_auth())
):
    """å–å¾—å–®ä¸€å…¬æ–‡è©³æƒ…ï¼ˆPOST-only è³‡å®‰æ©Ÿåˆ¶ï¼Œå«æ“´å……æ¬„ä½èˆ‡æ¬Šé™æª¢æŸ¥ï¼‰"""
    try:
        query = select(OfficialDocument).where(OfficialDocument.id == document_id)
        result = await db.execute(query)
        document = result.scalar_one_or_none()

        if not document:
            from fastapi.responses import JSONResponse
            return JSONResponse(
                status_code=404,
                content={
                    "success": False,
                    "error": {
                        "code": "ERR_NOT_FOUND",
                        "message": f"å…¬æ–‡ (ID: {document_id}) ä¸å­˜åœ¨"
                    }
                }
            )

        # ðŸ”’ è¡Œç´šåˆ¥æ¬Šé™æª¢æŸ¥ (RLS)
        if not current_user.is_admin and not current_user.is_superuser:
            # æª¢æŸ¥ä½¿ç”¨è€…æ˜¯å¦æœ‰æ¬Šé™æŸ¥çœ‹æ­¤å…¬æ–‡
            if document.contract_project_id:
                # å…¬æ–‡æœ‰é—œè¯å°ˆæ¡ˆï¼Œæª¢æŸ¥ä½¿ç”¨è€…æ˜¯å¦ç‚ºå°ˆæ¡ˆæˆå“¡
                access_check = await db.execute(
                    select(project_user_assignment.c.id).where(
                        and_(
                            project_user_assignment.c.project_id == document.contract_project_id,
                            project_user_assignment.c.user_id == current_user.id,
                            project_user_assignment.c.status.in_(['active', 'Active', None])
                        )
                    ).limit(1)
                )
                if not access_check.scalar_one_or_none():
                    raise ForbiddenException("æ‚¨æ²’æœ‰æ¬Šé™æŸ¥çœ‹æ­¤å…¬æ–‡")
            # ç„¡å°ˆæ¡ˆé—œè¯çš„å…¬æ–‡è¦–ç‚ºå…¬é–‹ï¼Œä¸éœ€é¡å¤–æª¢æŸ¥

        # æº–å‚™æ“´å……æ¬„ä½
        doc_dict = {k: v for k, v in document.__dict__.items() if not k.startswith('_')}

        # æŸ¥è©¢æ‰¿æ”¬æ¡ˆä»¶åç¨±
        if document.contract_project_id:
            project_query = select(ContractProject.project_name).where(
                ContractProject.id == document.contract_project_id
            )
            project_result = await db.execute(project_query)
            doc_dict['contract_project_name'] = project_result.scalar()

        # æŸ¥è©¢æ©Ÿé—œåç¨±ï¼ˆ2026-01-08 æ–°å¢žï¼‰
        if document.sender_agency_id:
            agency_query = select(GovernmentAgency.agency_name).where(
                GovernmentAgency.id == document.sender_agency_id
            )
            agency_result = await db.execute(agency_query)
            doc_dict['sender_agency_name'] = agency_result.scalar()

        if document.receiver_agency_id:
            agency_query = select(GovernmentAgency.agency_name).where(
                GovernmentAgency.id == document.receiver_agency_id
            )
            agency_result = await db.execute(agency_query)
            doc_dict['receiver_agency_name'] = agency_result.scalar()

        # æŸ¥è©¢é™„ä»¶æ•¸é‡
        attachment_count_query = select(func.count(DocumentAttachment.id)).where(
            DocumentAttachment.document_id == document_id
        )
        attachment_result = await db.execute(attachment_count_query)
        doc_dict['attachment_count'] = attachment_result.scalar() or 0

        return DocumentResponse.model_validate(doc_dict)
    except Exception as e:
        logger.error(f"å–å¾—å…¬æ–‡è©³æƒ…å¤±æ•—: {e}", exc_info=True)
        from fastapi.responses import JSONResponse
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error": {
                    "code": "ERR_INTERNAL",
                    "message": f"å–å¾—å…¬æ–‡è©³æƒ…å¤±æ•—: {str(e)}"
                }
            }
        )


@router.post(
    "",
    response_model=DocumentResponse,
    summary="å»ºç«‹å…¬æ–‡"
)
async def create_document(
    data: DocumentCreateRequest = Body(...),
    db: AsyncSession = Depends(get_async_db),
    current_user: User = Depends(require_permission("documents:create"))
):
    """
    å»ºç«‹æ–°å…¬æ–‡ï¼ˆPOST-only è³‡å®‰æ©Ÿåˆ¶ï¼Œå«ä½¿ç”¨è€…è¿½è¹¤ï¼‰

    ðŸ”’ æ¬Šé™è¦æ±‚ï¼šdocuments:create
    """
    try:
        create_data = data.model_dump(exclude_unset=True)

        # OfficialDocument æ¨¡åž‹çš„æœ‰æ•ˆæ¬„ä½ï¼ˆèˆ‡è³‡æ–™åº« schema å°é½Šï¼‰
        valid_model_fields = {
            'auto_serial', 'doc_number', 'doc_type', 'subject', 'sender', 'receiver',
            'doc_date', 'receive_date', 'send_date', 'status', 'category',
            'delivery_method', 'has_attachment', 'contract_project_id',
            'sender_agency_id', 'receiver_agency_id', 'title', 'cloud_file_link',
            'dispatch_format', 'assignee', 'notes', 'ck_note', 'content'
        }

        # éŽæ¿¾æŽ‰ä¸å­˜åœ¨æ–¼æ¨¡åž‹çš„æ¬„ä½ï¼ˆé¿å… TypeErrorï¼‰
        filtered_data = {k: v for k, v in create_data.items() if k in valid_model_fields}

        # è‡ªå‹•ç”¢ç”Ÿ auto_serialï¼ˆè‹¥æœªæä¾›ï¼‰
        if not filtered_data.get('auto_serial'):
            doc_type = filtered_data.get('doc_type', 'æ”¶æ–‡')
            prefix = 'R' if doc_type == 'æ”¶æ–‡' else 'S'
            # æŸ¥è©¢ç•¶å‰æœ€å¤§æµæ°´è™Ÿ
            result = await db.execute(
                select(func.max(OfficialDocument.auto_serial)).where(
                    OfficialDocument.auto_serial.like(f'{prefix}%')
                )
            )
            max_serial = result.scalar_one_or_none()
            if max_serial:
                try:
                    num = int(max_serial[1:]) + 1
                except (ValueError, IndexError):
                    num = 1
            else:
                num = 1
            filtered_data['auto_serial'] = f'{prefix}{num:04d}'

        # æ—¥æœŸæ¬„ä½éœ€è¦ç‰¹åˆ¥è™•ç†ï¼šå­—ä¸²è½‰æ›ç‚º date ç‰©ä»¶
        date_fields = ['doc_date', 'receive_date', 'send_date']
        for field in date_fields:
            if field in filtered_data and isinstance(filtered_data[field], str):
                filtered_data[field] = parse_date_string(filtered_data[field])

        document = OfficialDocument(**filtered_data)
        db.add(document)
        await db.commit()
        await db.refresh(document)

        # å¯©è¨ˆæ—¥èªŒï¼ˆä½¿ç”¨ AuditServiceï¼Œè‡ªå‹•ä½¿ç”¨ç¨ç«‹ sessionï¼Œä¸æœƒæ±¡æŸ“ä¸»äº¤æ˜“ï¼‰
        user_id = current_user.id if current_user else None
        user_name = current_user.username if current_user else "Anonymous"
        logger.info(f"å…¬æ–‡ {document.id} å»ºç«‹ by {user_name}")

        from app.services.audit_service import AuditService
        await AuditService.log_document_change(
            document_id=document.id,
            action="CREATE",
            changes={"created": filtered_data},
            user_id=user_id,
            user_name=user_name,
            source="API"
        )

        return DocumentResponse.model_validate(document)
    except Exception as e:
        await db.rollback()
        logger.error(f"å»ºç«‹å…¬æ–‡å¤±æ•—: {e}", exc_info=True)
        raise


@router.post(
    "/{document_id}/update",
    response_model=DocumentResponse,
    summary="æ›´æ–°å…¬æ–‡"
)
async def update_document(
    document_id: int,
    data: DocumentUpdateRequest = Body(...),
    db: AsyncSession = Depends(get_async_db),
    current_user: User = Depends(require_permission("documents:edit"))
):
    """
    æ›´æ–°å…¬æ–‡ï¼ˆPOST-only è³‡å®‰æ©Ÿåˆ¶ï¼Œå«å¯©è¨ˆæ—¥èªŒèˆ‡ä½¿ç”¨è€…è¿½è¹¤ï¼‰

    ðŸ”’ æ¬Šé™è¦æ±‚ï¼šdocuments:edit
    ðŸ”’ è¡Œç´šåˆ¥æ¬Šé™ï¼šä¸€èˆ¬ä½¿ç”¨è€…åªèƒ½ç·¨è¼¯é—œè¯å°ˆæ¡ˆçš„å…¬æ–‡
    """
    try:
        logger.info(f"[æ›´æ–°å…¬æ–‡] é–‹å§‹æ›´æ–°å…¬æ–‡ ID: {document_id}")
        logger.debug(f"[æ›´æ–°å…¬æ–‡] æ”¶åˆ°è³‡æ–™: {data.model_dump()}")

        query = select(OfficialDocument).where(OfficialDocument.id == document_id)
        result = await db.execute(query)
        document = result.scalar_one_or_none()

        if not document:
            raise NotFoundException(resource="å…¬æ–‡", resource_id=document_id)

        # ðŸ”’ è¡Œç´šåˆ¥æ¬Šé™æª¢æŸ¥ (RLS) - éžç®¡ç†å“¡åªèƒ½ç·¨è¼¯é—œè¯å°ˆæ¡ˆçš„å…¬æ–‡
        if not current_user.is_admin and not current_user.is_superuser:
            if document.contract_project_id:
                access_check = await db.execute(
                    select(project_user_assignment.c.id).where(
                        and_(
                            project_user_assignment.c.project_id == document.contract_project_id,
                            project_user_assignment.c.user_id == current_user.id,
                            project_user_assignment.c.status.in_(['active', 'Active', None])
                        )
                    ).limit(1)
                )
                if not access_check.scalar_one_or_none():
                    raise ForbiddenException("æ‚¨æ²’æœ‰æ¬Šé™ç·¨è¼¯æ­¤å…¬æ–‡")

        # åˆå§‹åŒ–å¯©è¨ˆä¿è­·å™¨ï¼Œè¨˜éŒ„åŽŸå§‹è³‡æ–™
        guard = DocumentUpdateGuard(db, document_id)
        original_data = {
            col.name: getattr(document, col.name)
            for col in document.__table__.columns
        }

        update_data = data.model_dump(exclude_unset=True)
        logger.debug(f"[æ›´æ–°å…¬æ–‡] éŽæ¿¾å‰ update_data: {update_data}")

        # OfficialDocument æ¨¡åž‹çš„æœ‰æ•ˆæ¬„ä½ï¼ˆèˆ‡è³‡æ–™åº« schema å°é½Šï¼‰
        valid_model_fields = {
            'auto_serial', 'doc_number', 'doc_type', 'subject', 'sender', 'receiver',
            'doc_date', 'receive_date', 'send_date', 'status', 'category',
            'delivery_method', 'has_attachment', 'contract_project_id',
            'sender_agency_id', 'receiver_agency_id', 'title', 'cloud_file_link',
            'dispatch_format', 'assignee', 'notes', 'ck_note', 'content'
        }

        # éŽæ¿¾æŽ‰ä¸å­˜åœ¨æ–¼æ¨¡åž‹çš„æ¬„ä½
        update_data = {k: v for k, v in update_data.items() if k in valid_model_fields}
        logger.debug(f"[æ›´æ–°å…¬æ–‡] éŽæ¿¾å¾Œ update_data: {update_data}")

        # æ—¥æœŸæ¬„ä½éœ€è¦ç‰¹åˆ¥è™•ç†ï¼šå­—ä¸²è½‰æ›ç‚º date ç‰©ä»¶
        date_fields = ['doc_date', 'receive_date', 'send_date']
        processed_data = {}

        for key, value in update_data.items():
            if value is not None:
                # è™•ç†æ—¥æœŸæ¬„ä½
                if key in date_fields:
                    parsed_date = parse_date_string(value) if isinstance(value, str) else value
                    setattr(document, key, parsed_date)
                    processed_data[key] = parsed_date
                else:
                    setattr(document, key, value)
                    processed_data[key] = value

        # è¨˜éŒ„å¯©è¨ˆæ—¥èªŒï¼ˆè®Šæ›´å‰å¾Œæ¯”å°ï¼‰
        changes = {}
        for key, new_value in processed_data.items():
            old_value = original_data.get(key)
            if old_value != new_value:
                changes[key] = {"old": str(old_value), "new": str(new_value)}

        # å…ˆæäº¤ä¸»è¦æ›´æ–°æ“ä½œ
        await db.commit()
        await db.refresh(document)

        # å¯©è¨ˆæ—¥èªŒå’Œé€šçŸ¥ï¼ˆä½¿ç”¨çµ±ä¸€æœå‹™ï¼Œè‡ªå‹•ç®¡ç†ç¨ç«‹ sessionï¼‰
        if changes:
            user_id = current_user.id if current_user else None
            user_name = current_user.username if current_user else "Anonymous"
            logger.info(f"å…¬æ–‡ {document_id} æ›´æ–° by {user_name}: {list(changes.keys())}")

            # ä½¿ç”¨ AuditServiceï¼ˆè‡ªå‹•ä½¿ç”¨ç¨ç«‹ sessionï¼Œä¸æœƒæ±¡æŸ“ä¸»äº¤æ˜“ï¼‰
            from app.services.audit_service import AuditService
            await AuditService.log_document_change(
                document_id=document_id,
                action="UPDATE",
                changes=changes,
                user_id=user_id,
                user_name=user_name,
                source="API"
            )

            # é—œéµæ¬„ä½è®Šæ›´é€šçŸ¥ï¼ˆä½¿ç”¨ safe_* æ–¹æ³•ï¼Œè‡ªå‹•ä½¿ç”¨ç¨ç«‹ sessionï¼‰
            critical_field_names = CRITICAL_FIELDS.get("documents", {})
            for field_key, change_info in changes.items():
                if field_key in critical_field_names:
                    await NotificationService.safe_notify_critical_change(
                        document_id=document_id,
                        field=field_key,
                        old_value=change_info.get("old", ""),
                        new_value=change_info.get("new", ""),
                        user_id=user_id,
                        user_name=user_name,
                        table_name="documents"
                    )

        return DocumentResponse.model_validate(document)
    except NotFoundException:
        raise
    except Exception as e:
        await db.rollback()
        logger.error(f"æ›´æ–°å…¬æ–‡å¤±æ•—: {e}", exc_info=True)
        raise


@router.post(
    "/{document_id}/delete",
    response_model=DeleteResponse,
    summary="åˆªé™¤å…¬æ–‡"
)
async def delete_document(
    document_id: int,
    db: AsyncSession = Depends(get_async_db),
    current_user: User = Depends(require_permission("documents:delete"))
):
    """
    åˆªé™¤å…¬æ–‡ï¼ˆPOST-only è³‡å®‰æ©Ÿåˆ¶ï¼‰

    ðŸ”’ æ¬Šé™è¦æ±‚ï¼šdocuments:delete
    ðŸ”’ è¡Œç´šåˆ¥æ¬Šé™ï¼šä¸€èˆ¬ä½¿ç”¨è€…åªèƒ½åˆªé™¤é—œè¯å°ˆæ¡ˆçš„å…¬æ–‡

    åŒæ­¥åˆªé™¤ï¼š
    - å…¬æ–‡è³‡æ–™åº«è¨˜éŒ„
    - é™„ä»¶è³‡æ–™åº«è¨˜éŒ„ï¼ˆCASCADEï¼‰
    - å¯¦é«”é™„ä»¶æª”æ¡ˆ
    - å…¬æ–‡é™„ä»¶è³‡æ–™å¤¾ï¼ˆè‹¥ç‚ºç©ºï¼‰
    """
    try:
        # 1. æŸ¥è©¢å…¬æ–‡æ˜¯å¦å­˜åœ¨
        query = select(OfficialDocument).where(OfficialDocument.id == document_id)
        result = await db.execute(query)
        document = result.scalar_one_or_none()

        if not document:
            raise NotFoundException(resource="å…¬æ–‡", resource_id=document_id)

        # ðŸ”’ è¡Œç´šåˆ¥æ¬Šé™æª¢æŸ¥ (RLS) - éžç®¡ç†å“¡åªèƒ½åˆªé™¤é—œè¯å°ˆæ¡ˆçš„å…¬æ–‡
        if not current_user.is_admin and not current_user.is_superuser:
            if document.contract_project_id:
                access_check = await db.execute(
                    select(project_user_assignment.c.id).where(
                        and_(
                            project_user_assignment.c.project_id == document.contract_project_id,
                            project_user_assignment.c.user_id == current_user.id,
                            project_user_assignment.c.status.in_(['active', 'Active', None])
                        )
                    ).limit(1)
                )
                if not access_check.scalar_one_or_none():
                    raise ForbiddenException("æ‚¨æ²’æœ‰æ¬Šé™åˆªé™¤æ­¤å…¬æ–‡")

        # 2. æŸ¥è©¢é—œè¯çš„é™„ä»¶è¨˜éŒ„ï¼ˆåœ¨åˆªé™¤å‰å–å¾—æª”æ¡ˆè·¯å¾‘ï¼‰
        attachment_query = select(DocumentAttachment).where(
            DocumentAttachment.document_id == document_id
        )
        attachment_result = await db.execute(attachment_query)
        attachments = attachment_result.scalars().all()

        # 3. æ”¶é›†éœ€è¦åˆªé™¤çš„æª”æ¡ˆè·¯å¾‘å’Œè³‡æ–™å¤¾
        file_paths_to_delete = []
        folders_to_check = set()

        for attachment in attachments:
            if attachment.file_path:
                file_paths_to_delete.append(attachment.file_path)
                # è¨˜éŒ„çˆ¶è³‡æ–™å¤¾è·¯å¾‘ï¼ˆdoc_{id} å±¤ç´šï¼‰
                parent_folder = os.path.dirname(attachment.file_path)
                if parent_folder:
                    folders_to_check.add(parent_folder)

        # 4. è¨˜éŒ„å…¬æ–‡è³‡è¨Šï¼ˆåœ¨åˆªé™¤å‰ä¿å­˜ï¼Œç”¨æ–¼å¾ŒçºŒå¯©è¨ˆæ—¥èªŒï¼‰
        user_id = current_user.id
        user_name = current_user.username
        doc_number = document.doc_number or ""
        subject = document.subject or ""
        attachments_count = len(attachments)
        logger.info(f"å…¬æ–‡ {document_id} åˆªé™¤ by {user_name}")

        # 5. åˆªé™¤è³‡æ–™åº«è¨˜éŒ„ï¼ˆCASCADE æœƒè‡ªå‹•åˆªé™¤ document_attachmentsï¼‰
        await db.delete(document)
        await db.commit()

        # 6. å¯©è¨ˆæ—¥èªŒå’Œé€šçŸ¥ï¼ˆä½¿ç”¨çµ±ä¸€æœå‹™ï¼Œè‡ªå‹•ç®¡ç†ç¨ç«‹ sessionï¼‰
        from app.services.audit_service import AuditService
        await AuditService.log_document_change(
            document_id=document_id,
            action="DELETE",
            changes={
                "deleted": {
                    "doc_number": doc_number,
                    "subject": subject,
                    "attachments_count": attachments_count
                }
            },
            user_id=user_id,
            user_name=user_name,
            source="API"
        )

        # å…¬æ–‡åˆªé™¤é€šçŸ¥ï¼ˆä½¿ç”¨ safe_* æ–¹æ³•ï¼Œè‡ªå‹•ä½¿ç”¨ç¨ç«‹ sessionï¼‰
        await NotificationService.safe_notify_document_deleted(
            document_id=document_id,
            doc_number=doc_number,
            subject=subject,
            user_id=user_id,
            user_name=user_name
        )

        # 7. åˆªé™¤å¯¦é«”æª”æ¡ˆï¼ˆåœ¨è³‡æ–™åº«æˆåŠŸåˆªé™¤å¾ŒåŸ·è¡Œï¼‰
        deleted_files = 0
        file_errors = []

        for file_path in file_paths_to_delete:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    deleted_files += 1
                    logger.info(f"å·²åˆªé™¤é™„ä»¶æª”æ¡ˆ: {file_path}")
            except Exception as e:
                file_errors.append(f"{file_path}: {str(e)}")
                logger.warning(f"åˆªé™¤é™„ä»¶æª”æ¡ˆå¤±æ•—: {file_path}, éŒ¯èª¤: {e}")

        # 8. å˜—è©¦åˆªé™¤ç©ºçš„å…¬æ–‡è³‡æ–™å¤¾ï¼ˆdoc_{id}ï¼‰
        deleted_folders = 0
        for folder in folders_to_check:
            try:
                if os.path.exists(folder) and os.path.isdir(folder):
                    # åªåˆªé™¤ç©ºè³‡æ–™å¤¾
                    if not os.listdir(folder):
                        os.rmdir(folder)
                        deleted_folders += 1
                        logger.info(f"å·²åˆªé™¤ç©ºè³‡æ–™å¤¾: {folder}")
            except Exception as e:
                logger.warning(f"åˆªé™¤è³‡æ–™å¤¾å¤±æ•—: {folder}, éŒ¯èª¤: {e}")

        # 9. å»ºæ§‹å›žæ‡‰è¨Šæ¯
        message = f"å…¬æ–‡å·²åˆªé™¤"
        if deleted_files > 0:
            message += f"ï¼ŒåŒæ­¥åˆªé™¤ {deleted_files} å€‹é™„ä»¶æª”æ¡ˆ"
        if deleted_folders > 0:
            message += f"ï¼Œæ¸…ç† {deleted_folders} å€‹ç©ºè³‡æ–™å¤¾"
        if file_errors:
            message += f"ï¼ˆ{len(file_errors)} å€‹æª”æ¡ˆåˆªé™¤å¤±æ•—ï¼‰"

        return DeleteResponse(
            success=True,
            message=message,
            deleted_id=document_id
        )
    except NotFoundException:
        raise
    except Exception as e:
        await db.rollback()
        logger.error(f"åˆªé™¤å…¬æ–‡å¤±æ•—: {e}", exc_info=True)
        raise


# ============================================================================
# å¯©è¨ˆæ—¥èªŒæŸ¥è©¢ API
# ============================================================================

@router.post(
    "/audit-logs",
    response_model=AuditLogResponse,
    summary="æŸ¥è©¢å¯©è¨ˆæ—¥èªŒ"
)
async def get_audit_logs(
    query: AuditLogQuery = Body(default=AuditLogQuery()),
    db: AsyncSession = Depends(get_async_db)
):
    """
    æŸ¥è©¢å¯©è¨ˆæ—¥èªŒ

    æ”¯æ´ä¾å…¬æ–‡ IDã€æ“ä½œé¡žåž‹ã€ä½¿ç”¨è€…ã€æ—¥æœŸç¯„åœç­‰æ¢ä»¶ç¯©é¸
    """
    try:
        # æ§‹å»ºæŸ¥è©¢æ¢ä»¶
        conditions = []
        params = {}

        if query.document_id:
            conditions.append("record_id = :document_id")
            params["document_id"] = query.document_id
        if query.table_name:
            conditions.append("table_name = :table_name")
            params["table_name"] = query.table_name
        if query.action:
            conditions.append("action = :action")
            params["action"] = query.action
        if query.user_id:
            conditions.append("user_id = :user_id")
            params["user_id"] = query.user_id
        if query.is_critical is not None:
            conditions.append("is_critical = :is_critical")
            params["is_critical"] = query.is_critical
        if query.date_from:
            conditions.append("created_at >= :date_from")
            params["date_from"] = query.date_from
        if query.date_to:
            conditions.append("created_at <= :date_to")
            params["date_to"] = query.date_to + " 23:59:59"

        where_clause = " AND ".join(conditions) if conditions else "1=1"

        # è¨ˆç®—ç¸½ç­†æ•¸
        count_sql = f"SELECT COUNT(*) FROM audit_logs WHERE {where_clause}"
        count_result = await db.execute(text(count_sql), params)
        total = count_result.scalar() or 0

        # æŸ¥è©¢è³‡æ–™ï¼ˆåˆ†é ï¼‰
        offset = (query.page - 1) * query.limit
        data_sql = f"""
            SELECT id, table_name, record_id, action, changes,
                   user_id, user_name, source, is_critical,
                   TO_CHAR(created_at, 'YYYY-MM-DD HH24:MI:SS') as created_at
            FROM audit_logs
            WHERE {where_clause}
            ORDER BY created_at DESC
            LIMIT :limit OFFSET :offset
        """
        params["limit"] = query.limit
        params["offset"] = offset

        result = await db.execute(text(data_sql), params)
        rows = result.fetchall()

        items = [
            AuditLogItem(
                id=row.id,
                table_name=row.table_name,
                record_id=row.record_id,
                action=row.action,
                changes=row.changes,
                user_id=row.user_id,
                user_name=row.user_name,
                source=row.source,
                is_critical=row.is_critical or False,
                created_at=row.created_at
            )
            for row in rows
        ]

        total_pages = (total + query.limit - 1) // query.limit

        return AuditLogResponse(
            success=True,
            items=items,
            pagination=PaginationMeta(
                total=total,
                page=query.page,
                limit=query.limit,
                total_pages=total_pages,
                has_next=query.page < total_pages,
                has_prev=query.page > 1
            )
        )
    except Exception as e:
        logger.error(f"æŸ¥è©¢å¯©è¨ˆæ—¥èªŒå¤±æ•—: {e}", exc_info=True)
        return AuditLogResponse(
            success=False,
            items=[],
            pagination=PaginationMeta(
                total=0, page=1, limit=query.limit,
                total_pages=0, has_next=False, has_prev=False
            )
        )


@router.post(
    "/{document_id}/audit-history",
    response_model=AuditLogResponse,
    summary="æŸ¥è©¢å…¬æ–‡è®Šæ›´æ­·å²"
)
async def get_document_audit_history(
    document_id: int,
    db: AsyncSession = Depends(get_async_db)
):
    """æŸ¥è©¢ç‰¹å®šå…¬æ–‡çš„è®Šæ›´æ­·å²è¨˜éŒ„"""
    query = AuditLogQuery(document_id=document_id, table_name="documents", limit=50)
    return await get_audit_logs(query, db)


# ============================================================================
# å‘å¾Œç›¸å®¹ï¼šä¿ç•™ GET ç«¯é»žï¼ˆå·²æ£„ç”¨ï¼Œå°‡åœ¨æœªä¾†ç‰ˆæœ¬ç§»é™¤ï¼‰
# ============================================================================

@router.post(
    "/integrated-search",
    summary="æ•´åˆå¼å…¬æ–‡æœå°‹ï¼ˆå·²æ£„ç”¨ï¼Œè«‹æ”¹ç”¨ POST /listï¼‰",
    deprecated=True
)
async def integrated_document_search_legacy(
    skip: int = Query(0, ge=0, description="è·³éŽç­†æ•¸"),
    limit: int = Query(50, ge=1, le=1000, description="å–å¾—ç­†æ•¸"),
    keyword: Optional[str] = Query(None, description="é—œéµå­—æœå°‹"),
    doc_type: Optional[str] = Query(None, description="å…¬æ–‡é¡žåž‹"),
    year: Optional[int] = Query(None, description="å¹´åº¦"),
    status: Optional[str] = Query(None, description="ç‹€æ…‹"),
    contract_case: Optional[str] = Query(None, description="æ‰¿æ”¬æ¡ˆä»¶"),
    sender: Optional[str] = Query(None, description="ç™¼æ–‡å–®ä½"),
    receiver: Optional[str] = Query(None, description="å—æ–‡å–®ä½"),
    doc_date_from: Optional[str] = Query(None, description="å…¬æ–‡æ—¥æœŸèµ·"),
    doc_date_to: Optional[str] = Query(None, description="å…¬æ–‡æ—¥æœŸè¿„"),
    sort_by: Optional[str] = Query("updated_at", description="æŽ’åºæ¬„ä½"),
    sort_order: Optional[str] = Query("desc", description="æŽ’åºé †åº"),
    db: AsyncSession = Depends(get_async_db)
):
    """
    æ•´åˆå¼å…¬æ–‡æœå°‹ï¼ˆå·²æ£„ç”¨ï¼‰

    è«‹æ”¹ç”¨ POST /documents-enhanced/list ç«¯é»ž
    """
    try:
        service = DocumentService(db)

        filters = DocumentFilter(
            keyword=keyword,
            doc_type=doc_type,
            year=year,
            status=status,
            sender=sender,
            receiver=receiver,
            date_from=doc_date_from,
            date_to=doc_date_to,
            sort_by=sort_by,
            sort_order=sort_order
        )

        if contract_case:
            setattr(filters, 'contract_case', contract_case)

        result = await service.get_documents(
            skip=skip,
            limit=limit,
            filters=filters
        )

        return result

    except Exception as e:
        logger.error(f"æ•´åˆæœå°‹å¤±æ•—: {e}", exc_info=True)
        return {"items": [], "total": 0, "page": 1, "limit": limit, "total_pages": 0}


@router.post("/document-years", summary="å–å¾—å¹´åº¦é¸é …ï¼ˆå·²æ£„ç”¨ï¼‰", deprecated=True)
async def get_document_years_legacy(db: AsyncSession = Depends(get_async_db)):
    """å·²æ£„ç”¨ï¼Œè«‹æ”¹ç”¨ POST /documents-enhanced/years"""
    return await get_document_years(db)


# ============================================================================
# å°ˆæ¡ˆé—œè¯å…¬æ–‡ APIï¼ˆè‡ªå‹•é—œè¯æ©Ÿåˆ¶ï¼‰
# ============================================================================

@router.post(
    "/by-project",
    response_model=DocumentListResponse,
    summary="æŸ¥è©¢å°ˆæ¡ˆé—œè¯å…¬æ–‡",
    description="æ ¹æ“š project_id è‡ªå‹•æŸ¥è©¢è©²å°ˆæ¡ˆçš„æ‰€æœ‰é—œè¯å…¬æ–‡"
)
async def get_documents_by_project(
    query: ProjectDocumentsQuery = Body(...),
    db: AsyncSession = Depends(get_async_db)
):
    """
    æ ¹æ“šå°ˆæ¡ˆ ID æŸ¥è©¢é—œè¯å…¬æ–‡ï¼ˆè‡ªå‹•é—œè¯æ©Ÿåˆ¶ï¼‰

    é—œè¯é‚è¼¯ï¼š
    ä¾æ“š documents.contract_project_id = project_id æŸ¥è©¢

    å›žå‚³è©²å°ˆæ¡ˆçš„æ‰€æœ‰å…¬æ–‡ç´€éŒ„
    """
    try:
        # æ§‹å»ºæŸ¥è©¢æ¢ä»¶ï¼šä¾ contract_project_id åŒ¹é…
        doc_query = select(OfficialDocument).where(
            OfficialDocument.contract_project_id == query.project_id
        ).order_by(
            OfficialDocument.doc_date.desc(),
            OfficialDocument.id.desc()
        )

        # è¨ˆç®—ç¸½æ•¸
        count_query = select(func.count()).select_from(doc_query.subquery())
        total_result = await db.execute(count_query)
        total = total_result.scalar() or 0

        # åˆ†é 
        skip = (query.page - 1) * query.limit
        doc_query = doc_query.offset(skip).limit(query.limit)

        result = await db.execute(doc_query)
        documents = result.scalars().all()

        # æŸ¥è©¢å°ˆæ¡ˆåç¨±ï¼ˆæ‰€æœ‰æ–‡ä»¶å…±ç”¨åŒä¸€å€‹å°ˆæ¡ˆï¼‰
        project_name = None
        if query.project_id:
            project_query = select(ContractProject.project_name).where(
                ContractProject.id == query.project_id
            )
            project_result = await db.execute(project_query)
            project_name = project_result.scalar()

        # æŸ¥è©¢å°ˆæ¡ˆæ‰¿è¾¦åŒä»ï¼ˆä½¿ç”¨ project_user_assignment é—œè¯è¡¨ï¼‰
        assigned_staff = []
        if query.project_id:
            # å¾žé—œè¯è¡¨æŸ¥è©¢å°ˆæ¡ˆæˆå“¡ï¼Œä¸¦ JOIN users è¡¨ç²å–å§“å
            staff_query = (
                select(
                    project_user_assignment.c.user_id,
                    project_user_assignment.c.role,
                    User.full_name,
                    User.username
                )
                .join(User, User.id == project_user_assignment.c.user_id)
                .where(
                    project_user_assignment.c.project_id == query.project_id,
                    project_user_assignment.c.status == 'active'
                )
            )
            staff_result = await db.execute(staff_query)
            staff_rows = staff_result.all()
            assigned_staff = [
                StaffInfo(
                    user_id=row.user_id,
                    name=row.full_name or row.username or f"User {row.user_id}",
                    role=row.role or "member"
                )
                for row in staff_rows
            ]

        # è½‰æ›ç‚ºå›žæ‡‰æ ¼å¼ï¼ˆåŒ…å«å°ˆæ¡ˆé—œè¯è³‡è¨Šï¼‰
        response_items = []
        for doc in documents:
            try:
                doc_dict = {
                    **{k: v for k, v in doc.__dict__.items() if not k.startswith('_')},
                    'contract_project_name': project_name,
                    'assigned_staff': assigned_staff
                }
                response_items.append(DocumentResponse.model_validate(doc_dict))
            except Exception as e:
                logger.warning(f"è½‰æ›å…¬æ–‡è³‡æ–™å¤±æ•—: {e}")
                continue

        return DocumentListResponse(
            items=response_items,
            pagination=PaginationMeta.create(
                total=total,
                page=query.page,
                limit=query.limit
            )
        )

    except Exception as e:
        logger.error(f"æŸ¥è©¢å°ˆæ¡ˆé—œè¯å…¬æ–‡å¤±æ•—: {e}", exc_info=True)
        return DocumentListResponse(
            items=[],
            pagination=PaginationMeta.create(total=0, page=1, limit=query.limit)
        )


# ============================================================================
# å…¬æ–‡åŒ¯å‡º API
# ============================================================================

@router.post("/export", summary="åŒ¯å‡ºå…¬æ–‡è³‡æ–™")
async def export_documents(
    query: DocumentExportQuery = Body(...),
    db: AsyncSession = Depends(get_async_db)
):
    """
    åŒ¯å‡ºå…¬æ–‡è³‡æ–™ç‚º CSV æ ¼å¼

    æ”¯æ´åŠŸèƒ½:
    - ä¾æŒ‡å®š ID åˆ—è¡¨åŒ¯å‡º
    - ä¾é¡žåˆ¥/å¹´åº¦ç¯©é¸å¾ŒåŒ¯å‡º
    - è‹¥æœªæŒ‡å®šæ¢ä»¶å‰‡åŒ¯å‡ºå…¨éƒ¨
    """
    try:
        # æ§‹å»ºæŸ¥è©¢
        doc_query = select(OfficialDocument).options(
            selectinload(OfficialDocument.contract_project)
        )

        # ç¯©é¸æ¢ä»¶
        conditions = []
        if query.document_ids:
            conditions.append(OfficialDocument.id.in_(query.document_ids))
        if query.category:
            conditions.append(OfficialDocument.category == query.category)
        if query.year:
            conditions.append(func.extract('year', OfficialDocument.doc_date) == query.year)

        if conditions:
            doc_query = doc_query.where(and_(*conditions))

        doc_query = doc_query.order_by(OfficialDocument.doc_date.desc())

        result = await db.execute(doc_query)
        documents = result.scalars().all()

        # ç”¢ç”Ÿ CSV
        output = io.StringIO()
        writer = csv.writer(output, quoting=csv.QUOTE_ALL)

        # å¯«å…¥æ¨™é¡Œåˆ—
        headers = [
            'åºè™Ÿ', 'å…¬æ–‡æ–‡è™Ÿ', 'ä¸»æ—¨', 'é¡žåˆ¥', 'ç™¼æ–‡/æ”¶æ–‡æ—¥æœŸ',
            'ç™¼æ–‡å–®ä½', 'å—æ–‡å–®ä½', 'æ‰¿æ”¬æ¡ˆä»¶', 'ç‹€æ…‹', 'å‚™è¨»'
        ]
        writer.writerow(headers)

        # å¯«å…¥è³‡æ–™åˆ—
        for idx, doc in enumerate(documents, start=1):
            contract_case_name = ""
            if doc.contract_project:
                contract_case_name = doc.contract_project.project_name or ""

            row = [
                doc.auto_serial or idx,
                doc.doc_number or "",
                doc.subject or "",
                doc.category or "",
                str(doc.doc_date) if doc.doc_date else "",
                doc.sender or "",
                doc.receiver or "",
                contract_case_name,
                doc.status or "",
                doc.notes or ""
            ]
            writer.writerow(row)

        # é‡ç½®æ¸¸æ¨™ä½ç½®
        output.seek(0)

        # å›žå‚³ CSV æª”æ¡ˆ
        from datetime import datetime
        filename = f"documents_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"

        return StreamingResponse(
            iter(['\ufeff' + output.getvalue()]),  # BOM for Excel UTF-8
            media_type="text/csv; charset=utf-8",
            headers={
                "Content-Disposition": f"attachment; filename={filename}"
            }
        )

    except Exception as e:
        logger.error(f"åŒ¯å‡ºå…¬æ–‡å¤±æ•—: {e}", exc_info=True)
        from fastapi import HTTPException
        raise HTTPException(status_code=500, detail=f"åŒ¯å‡ºå…¬æ–‡å¤±æ•—: {str(e)}")


# ============================================================================
# Excel åŒ¯å‡ºç«¯é»ž
# ============================================================================

@router.post("/export/excel", summary="åŒ¯å‡ºå…¬æ–‡ç‚º Excel")
async def export_documents_excel(
    request: ExcelExportRequest = Body(default=ExcelExportRequest()),
    db: AsyncSession = Depends(get_async_db)
):
    """
    åŒ¯å‡ºå…¬æ–‡è³‡æ–™ç‚º Excel æ ¼å¼ (.xlsx)

    æª”åæ ¼å¼: CKå…¬æ–‡YYYYMMDD.xlsx

    æ”¯æ´åŠŸèƒ½:
    - ä¾æŒ‡å®š ID åˆ—è¡¨åŒ¯å‡º
    - ä¾é¡žåˆ¥/å¹´åº¦/é—œéµå­—/ç‹€æ…‹ç¯©é¸å¾ŒåŒ¯å‡º
    - è‹¥æœªæŒ‡å®šæ¢ä»¶å‰‡åŒ¯å‡ºå…¨éƒ¨ï¼ˆç„¡ç­†æ•¸é™åˆ¶ï¼‰

    æµæ°´è™Ÿèªªæ˜Ž:
    - S é–‹é ­: ç™¼æ–‡ (Send)
    - R é–‹é ­: æ”¶æ–‡ (Receive)
    """
    try:
        import pandas as pd
        from io import BytesIO
        from datetime import datetime

        # æ§‹å»ºæŸ¥è©¢ - ç„¡ç­†æ•¸é™åˆ¶ï¼ŒåŒ¯å‡ºå…¨éƒ¨ç¬¦åˆæ¢ä»¶çš„è³‡æ–™
        doc_query = select(OfficialDocument).options(
            selectinload(OfficialDocument.contract_project),
            selectinload(OfficialDocument.sender_agency),
            selectinload(OfficialDocument.receiver_agency),
            selectinload(OfficialDocument.attachments)  # è¼‰å…¥é™„ä»¶ä»¥çµ±è¨ˆæ•¸é‡
        )

        # ç¯©é¸æ¢ä»¶
        conditions = []
        if request.document_ids:
            conditions.append(OfficialDocument.id.in_(request.document_ids))
        if request.category:
            conditions.append(OfficialDocument.category == request.category)
        if request.year:
            conditions.append(func.extract('year', OfficialDocument.doc_date) == request.year)
        if request.status:
            conditions.append(OfficialDocument.status == request.status)
        if request.keyword:
            keyword = f"%{request.keyword}%"
            conditions.append(
                or_(
                    OfficialDocument.subject.ilike(keyword),
                    OfficialDocument.doc_number.ilike(keyword),
                    OfficialDocument.sender.ilike(keyword),
                    OfficialDocument.receiver.ilike(keyword),
                    OfficialDocument.content.ilike(keyword),
                    OfficialDocument.notes.ilike(keyword)
                )
            )
        if request.contract_case:
            # contract_case éœ€è¦é€éŽé—œè¯æŸ¥è©¢ ContractProject.project_name
            contract_case_keyword = f"%{request.contract_case}%"
            doc_query = doc_query.outerjoin(ContractProject, OfficialDocument.contract_project_id == ContractProject.id)
            conditions.append(ContractProject.project_name.ilike(contract_case_keyword))
        if request.sender:
            sender_keyword = f"%{request.sender}%"
            conditions.append(OfficialDocument.sender.ilike(sender_keyword))
        if request.receiver:
            receiver_keyword = f"%{request.receiver}%"
            conditions.append(OfficialDocument.receiver.ilike(receiver_keyword))

        if conditions:
            doc_query = doc_query.where(and_(*conditions))

        # æŽ’åºï¼šä¾å…¬æ–‡æ—¥æœŸé™åº
        doc_query = doc_query.order_by(OfficialDocument.doc_date.desc())

        result = await db.execute(doc_query)
        documents = result.scalars().all()

        if not documents:
            from fastapi import HTTPException
            raise HTTPException(status_code=404, detail="æ²’æœ‰ç¬¦åˆæ¢ä»¶çš„å…¬æ–‡å¯ä¾›åŒ¯å‡º")

        # è½‰æ›ç‚º DataFrame - ç²¾ç°¡æ¬„ä½
        data = []

        def clean_agency_name(raw_text: str, agency_name: str = "") -> str:
            """æ¸…ç†æ©Ÿé—œåç¨±ï¼Œç§»é™¤ä»£ç¢¼ï¼Œåªä¿ç•™ä¸­æ–‡åç¨±"""
            # å„ªå…ˆä½¿ç”¨é—œè¯è¡¨çš„æ©Ÿé—œåç¨±
            if agency_name:
                return agency_name
            if not raw_text:
                return ""
            # ç§»é™¤å¸¸è¦‹ä»£ç¢¼æ ¼å¼ï¼š
            # "EB50819619 ä¹¾å¤æ¸¬ç¹ªç§‘æŠ€æœ‰é™å…¬å¸" â†’ "ä¹¾å¤æ¸¬ç¹ªç§‘æŠ€æœ‰é™å…¬å¸"
            # "376470600A (å½°åŒ–ç¸£å’Œç¾Žåœ°æ”¿äº‹å‹™æ‰€)" â†’ "å½°åŒ–ç¸£å’Œç¾Žåœ°æ”¿äº‹å‹™æ‰€"
            # "376470600A\n(å½°åŒ–ç¸£å’Œç¾Žåœ°æ”¿äº‹å‹™æ‰€)" â†’ "å½°åŒ–ç¸£å’Œç¾Žåœ°æ”¿äº‹å‹™æ‰€"
            import re
            text = raw_text.strip()
            # ç§»é™¤æ‹¬è™Ÿå…§çš„å…§å®¹æå–ç‚ºä¸»åç¨±
            paren_match = re.search(r'[ï¼ˆ(]([^)ï¼‰]+)[)ï¼‰]', text)
            if paren_match:
                return paren_match.group(1).strip()
            # ç§»é™¤é–‹é ­çš„è‹±æ•¸ä»£ç¢¼ï¼ˆå¦‚ EB50819619ã€376470600Aï¼‰
            text = re.sub(r'^[A-Za-z0-9]+\s*', '', text)
            return text.strip()

        def get_valid_doc_type(doc_type: str) -> str:
            """å–å¾—æœ‰æ•ˆçš„å…¬æ–‡é¡žåž‹

            æœ‰æ•ˆå€¼: å‡½ã€é–‹æœƒé€šçŸ¥å–®ã€æœƒå‹˜é€šçŸ¥å–®ã€æ›¸å‡½ç­‰
            æ³¨æ„: 2026-01-07 å·²ä¿®å¾© 8 ç­†éŒ¯èª¤è³‡æ–™ï¼ˆdoc_type èª¤ç‚ºæ”¶æ–‡/ç™¼æ–‡ï¼‰
            """
            # ä¿ç•™é˜²è­·ï¼šè‹¥ä»æœ‰éŒ¯èª¤å€¼å‰‡éŽæ¿¾
            if doc_type in ['æ”¶æ–‡', 'ç™¼æ–‡']:
                return ""
            return doc_type or ""

        for doc in documents:
            # å–å¾—é—œè¯è³‡æ–™
            contract_case_name = ""
            if doc.contract_project:
                contract_case_name = doc.contract_project.project_name or ""

            sender_agency_name = ""
            if doc.sender_agency:
                sender_agency_name = doc.sender_agency.agency_name or ""

            receiver_agency_name = ""
            if doc.receiver_agency:
                receiver_agency_name = doc.receiver_agency.agency_name or ""

            # çµ±è¨ˆé™„ä»¶æ•¸é‡
            attachment_count = len(doc.attachments) if doc.attachments else 0
            attachment_text = f"{attachment_count} å€‹é™„ä»¶" if attachment_count > 0 else "ç„¡"

            # æ¬„ä½é †åºä¾éœ€æ±‚èª¿æ•´ï¼ˆå…¬æ–‡IDå°æ‡‰é™„ä»¶è³‡æ–™å¤¾ doc_{id}ï¼‰
            data.append({
                "å…¬æ–‡ID": doc.id,
                "æµæ°´è™Ÿ": doc.auto_serial or "",
                "ç™¼æ–‡å½¢å¼": doc.delivery_method or "",
                "é¡žåˆ¥": doc.category or "",
                "å…¬æ–‡é¡žåž‹": get_valid_doc_type(doc.doc_type),
                "å…¬æ–‡å­—è™Ÿ": doc.doc_number or "",
                "ä¸»æ—¨": doc.subject or "",
                "èªªæ˜Ž": getattr(doc, 'content', '') or "",
                "å…¬æ–‡æ—¥æœŸ": str(doc.doc_date) if doc.doc_date else "",
                "æ”¶æ–‡æ—¥æœŸ": str(doc.receive_date) if doc.receive_date else "",
                "ç™¼æ–‡æ—¥æœŸ": str(doc.send_date) if doc.send_date else "",
                "ç™¼æ–‡å–®ä½": clean_agency_name(doc.sender or "", sender_agency_name),
                "å—æ–‡å–®ä½": clean_agency_name(doc.receiver or "", receiver_agency_name),
                "é™„ä»¶ç´€éŒ„": attachment_text,
                "å‚™è¨»": getattr(doc, 'notes', '') or "",
                "ç‹€æ…‹": doc.status or "",
                "æ‰¿æ”¬æ¡ˆä»¶": contract_case_name,
                "å»ºç«‹æ™‚é–“": str(doc.created_at) if doc.created_at else "",
                "æ›´æ–°æ™‚é–“": str(doc.updated_at) if doc.updated_at else "",
            })

        df = pd.DataFrame(data)

        # ç”¢ç”Ÿ Excel
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='å…¬æ–‡æ¸…å–®')

            # å–å¾—å·¥ä½œè¡¨
            worksheet = writer.sheets['å…¬æ–‡æ¸…å–®']

            # è¡¨é ­æ¨£å¼ï¼šç²—é«” + æ·ºè—è‰²èƒŒæ™¯
            from openpyxl.styles import Font, PatternFill, Alignment, Border, Side
            header_font = Font(bold=True, color="000000")
            header_fill = PatternFill(start_color="CCE5FF", end_color="CCE5FF", fill_type="solid")
            header_alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )

            # å¥—ç”¨è¡¨é ­æ¨£å¼
            for cell in worksheet[1]:
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment
                cell.border = thin_border

            # è³‡æ–™åˆ—æ¨£å¼
            data_alignment = Alignment(vertical="center", wrap_text=True)
            for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row):
                for cell in row:
                    cell.alignment = data_alignment
                    cell.border = thin_border

            # èª¿æ•´æ¬„ä½å¯¬åº¦
            for idx, col in enumerate(df.columns):
                max_length = max(
                    df[col].astype(str).map(len).max(),
                    len(col)
                ) + 2
                # é™åˆ¶æœ€å¤§å¯¬åº¦
                max_length = min(max_length, 60)
                # Excel æ¬„ä½åç¨± A-Z, AA-AZ...
                col_letter = chr(65 + idx) if idx < 26 else f"A{chr(65 + idx - 26)}"
                worksheet.column_dimensions[col_letter].width = max_length

            # å‡çµè¡¨é ­åˆ—
            worksheet.freeze_panes = 'A2'

            # æ–°å¢žçµ±è¨ˆæ‘˜è¦å·¥ä½œè¡¨
            summary_data = {
                "é …ç›®": [
                    "åŒ¯å‡ºæ™‚é–“",
                    "å…¬æ–‡ç¸½æ•¸",
                    "æ”¶æ–‡æ•¸é‡",
                    "ç™¼æ–‡æ•¸é‡",
                    "æœ‰é™„ä»¶å…¬æ–‡",
                    "å·²æŒ‡æ´¾æ¡ˆä»¶",
                    "æœ€æ—©å…¬æ–‡æ—¥æœŸ",
                    "æœ€æ–°å…¬æ–‡æ—¥æœŸ"
                ],
                "æ•¸å€¼": [
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    str(len(documents)),
                    str(sum(1 for d in documents if d.category == 'æ”¶æ–‡')),
                    str(sum(1 for d in documents if d.category == 'ç™¼æ–‡')),
                    str(sum(1 for d in documents if d.attachments and len(d.attachments) > 0)),
                    str(sum(1 for d in documents if d.contract_project_id)),
                    str(min((d.doc_date for d in documents if d.doc_date), default="")) or "N/A",
                    str(max((d.doc_date for d in documents if d.doc_date), default="")) or "N/A"
                ]
            }
            summary_df = pd.DataFrame(summary_data)
            summary_df.to_excel(writer, index=False, sheet_name='çµ±è¨ˆæ‘˜è¦')

            # çµ±è¨ˆæ‘˜è¦å·¥ä½œè¡¨æ¨£å¼
            summary_ws = writer.sheets['çµ±è¨ˆæ‘˜è¦']
            for cell in summary_ws[1]:
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment
                cell.border = thin_border
            for row in summary_ws.iter_rows(min_row=2, max_row=summary_ws.max_row):
                for cell in row:
                    cell.alignment = data_alignment
                    cell.border = thin_border
            summary_ws.column_dimensions['A'].width = 20
            summary_ws.column_dimensions['B'].width = 30

        output.seek(0)

        # ç”¢ç”Ÿæª”å: ä¹¾å¤æ¸¬ç¹ªå…¬æ–‡ç¸½è¡¨YYYYMMDD.xlsx
        from urllib.parse import quote
        date_str = datetime.now().strftime('%Y%m%d')
        filename_cn = f"ä¹¾å¤æ¸¬ç¹ªå…¬æ–‡ç¸½è¡¨{date_str}.xlsx"
        filename_encoded = quote(filename_cn)

        return StreamingResponse(
            iter([output.getvalue()]),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={
                "Content-Disposition": f"attachment; filename*=UTF-8''{filename_encoded}",
                "X-Content-Type-Options": "nosniff",
                "Cache-Control": "no-cache, no-store, must-revalidate",
            }
        )

    except Exception as e:
        logger.error(f"åŒ¯å‡º Excel å¤±æ•—: {e}", exc_info=True)
        from fastapi import HTTPException
        raise HTTPException(status_code=500, detail=f"åŒ¯å‡º Excel å¤±æ•—: {str(e)}")


# ============================================================================
# Excel åŒ¯å…¥ï¼ˆæ‰‹å‹•å…¬æ–‡åŒ¯å…¥ï¼‰
# ============================================================================

@router.post("/import/excel/preview", summary="Excel åŒ¯å…¥é è¦½")
async def preview_excel_import(
    file: UploadFile = File(..., description="è¦é è¦½çš„ Excel æª”æ¡ˆï¼ˆ.xlsxï¼‰"),
    preview_rows: int = Query(default=10, ge=1, le=50, description="é è¦½ç­†æ•¸"),
    check_duplicates: bool = Query(default=True, description="æ˜¯å¦æª¢æŸ¥è³‡æ–™åº«é‡è¤‡"),
    db: AsyncSession = Depends(get_async_db)
):
    """
    é è¦½ Excel æª”æ¡ˆå…§å®¹ï¼ˆä¸åŸ·è¡ŒåŒ¯å…¥ï¼‰

    åŠŸèƒ½ï¼š
    - é¡¯ç¤ºå‰ N ç­†è³‡æ–™é è¦½
    - é©—è­‰æ¬„ä½æ ¼å¼
    - æ¨™ç¤ºå¯èƒ½çš„å•é¡Œï¼ˆé‡è¤‡ã€ç¼ºæ¬„ä½ç­‰ï¼‰
    - æª¢æŸ¥è³‡æ–™åº«ä¸­å·²å­˜åœ¨çš„å…¬æ–‡å­—è™Ÿ
    - çµ±è¨ˆé è¨ˆæ–°å¢ž/æ›´æ–°ç­†æ•¸

    ä½¿ç”¨æƒ…å¢ƒï¼š
    - ä½¿ç”¨è€…ä¸Šå‚³æª”æ¡ˆå¾Œï¼Œå…ˆé è¦½ç¢ºèªå†æ­£å¼åŒ¯å…¥
    """
    from fastapi import HTTPException

    if not file.filename:
        raise HTTPException(status_code=400, detail="æœªæä¾›æª”æ¡ˆ")

    if not file.filename.endswith(('.xlsx', '.xls')):
        raise HTTPException(
            status_code=400,
            detail="æª”æ¡ˆæ ¼å¼ä¸æ­£ç¢ºï¼Œåƒ…æ”¯æ´ Excel æª”æ¡ˆï¼ˆ.xlsx, .xlsï¼‰"
        )

    try:
        file_content = await file.read()
        filename = file.filename

        logger.info(f"Excel åŒ¯å…¥é è¦½: {filename}, å¤§å°: {len(file_content)} bytes")

        from app.services.excel_import_service import ExcelImportService
        import_service = ExcelImportService(db)
        result = await import_service.preview_excel(
            file_content, filename, preview_rows, check_duplicates
        )

        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Excel é è¦½å¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"é è¦½å¤±æ•—: {str(e)}")


@router.post("/import/excel", summary="æ‰‹å‹•å…¬æ–‡åŒ¯å…¥ï¼ˆExcelï¼‰")
async def import_documents_excel(
    file: UploadFile = File(..., description="è¦åŒ¯å…¥çš„ Excel æª”æ¡ˆï¼ˆ.xlsxï¼‰"),
    db: AsyncSession = Depends(get_async_db)
):
    """
    å¾ž Excel æª”æ¡ˆåŒ¯å…¥å…¬æ–‡è³‡æ–™ï¼ˆæ‰‹å‹•å…¬æ–‡åŒ¯å…¥ï¼‰

    é©ç”¨æƒ…å¢ƒï¼š
    - ç´™æœ¬éƒµå¯„ç´€éŒ„
    - æ‰‹å‹•è¼¸å…¥çš„å…¬æ–‡è³‡æ–™
    - åŒ¯å‡ºå¾Œä¿®æ”¹å†åŒ¯å…¥

    åŒ¯å…¥è¦å‰‡ï¼š
    - å…¬æ–‡ID æœ‰å€¼ï¼šæ›´æ–°ç¾æœ‰è³‡æ–™
    - å…¬æ–‡ID ç©ºç™½ï¼šæ–°å¢žè³‡æ–™ï¼ˆè‡ªå‹•ç”Ÿæˆæµæ°´è™Ÿï¼‰
    - å¿…å¡«æ¬„ä½ï¼šå…¬æ–‡å­—è™Ÿã€ä¸»æ—¨ã€é¡žåˆ¥

    èˆ‡ã€Œé›»å­å…¬æ–‡æª”åŒ¯å…¥ã€(CSV) çš„å·®ç•°ï¼š
    - CSV åŒ¯å…¥ï¼šé›»å­å…¬æ–‡ç³»çµ±åŒ¯å‡ºçš„å›ºå®šæ ¼å¼
    - Excel åŒ¯å…¥ï¼šæœ¬ç³»çµ±åŒ¯å‡ºæ ¼å¼ï¼Œæ”¯æ´æ–°å¢ž/æ›´æ–°
    """
    from fastapi import HTTPException

    # é©—è­‰æª”æ¡ˆæ ¼å¼
    if not file.filename:
        raise HTTPException(status_code=400, detail="æœªæä¾›æª”æ¡ˆ")

    if not file.filename.endswith(('.xlsx', '.xls')):
        raise HTTPException(
            status_code=400,
            detail="æª”æ¡ˆæ ¼å¼ä¸æ­£ç¢ºï¼Œåƒ…æ”¯æ´ Excel æª”æ¡ˆï¼ˆ.xlsx, .xlsï¼‰"
        )

    try:
        # è®€å–æª”æ¡ˆå…§å®¹
        file_content = await file.read()
        filename = file.filename

        logger.info(f"é–‹å§‹ Excel åŒ¯å…¥: {filename}, å¤§å°: {len(file_content)} bytes")

        # ä½¿ç”¨ ExcelImportService è™•ç†
        from app.services.excel_import_service import ExcelImportService
        import_service = ExcelImportService(db)
        result = await import_service.import_from_excel(file_content, filename)

        return result

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Excel åŒ¯å…¥å¤±æ•—: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Excel åŒ¯å…¥å¤±æ•—: {str(e)}")


@router.post("/import/excel/template", summary="ä¸‹è¼‰ Excel åŒ¯å…¥ç¯„æœ¬")
async def download_excel_template():
    """
    ä¸‹è¼‰ Excel åŒ¯å…¥ç¯„æœ¬

    ç¯„æœ¬åŒ…å«ï¼š
    - æ¨™é¡Œåˆ—ï¼ˆæ¬„ä½åç¨±ï¼‰
    - ç¯„ä¾‹è³‡æ–™ï¼ˆ1-2 ç­†ï¼‰
    - æ¬„ä½èªªæ˜Ž
    """
    try:
        import pandas as pd
        from io import BytesIO
        from urllib.parse import quote

        # å»ºç«‹ç¯„æœ¬è³‡æ–™ï¼ˆæ¬„ä½é †åºèˆ‡åŒ¯å‡ºä¸€è‡´ï¼š19 æ¬„ï¼‰
        template_data = [
            {
                "å…¬æ–‡ID": "",  # ç©ºç™½=æ–°å¢ž
                "æµæ°´è™Ÿ": "",  # ç³»çµ±è‡ªå‹•ç”Ÿæˆ
                "ç™¼æ–‡å½¢å¼": "ç´™æœ¬éƒµå¯„",
                "é¡žåˆ¥": "æ”¶æ–‡",
                "å…¬æ–‡é¡žåž‹": "å‡½",
                "å…¬æ–‡å­—è™Ÿ": "XXå­—ç¬¬1140000001è™Ÿ",
                "ä¸»æ—¨": "ï¼ˆè«‹è¼¸å…¥å…¬æ–‡ä¸»æ—¨ï¼‰",
                "èªªæ˜Ž": "ï¼ˆè«‹è¼¸å…¥å…¬æ–‡å…§å®¹èªªæ˜Žï¼‰",
                "å…¬æ–‡æ—¥æœŸ": "2026-01-07",
                "æ”¶æ–‡æ—¥æœŸ": "2026-01-07",
                "ç™¼æ–‡æ—¥æœŸ": "",
                "ç™¼æ–‡å–®ä½": "â—‹â—‹å–®ä½",
                "å—æ–‡å–®ä½": "ä¹¾å¤æ¸¬ç¹ªç§‘æŠ€æœ‰é™å…¬å¸",
                "é™„ä»¶ç´€éŒ„": "",  # åƒ…ä¾›åƒè€ƒï¼ŒåŒ¯å…¥å¿½ç•¥
                "å‚™è¨»": "",
                "ç‹€æ…‹": "active",
                "æ‰¿æ”¬æ¡ˆä»¶": "",
                "å»ºç«‹æ™‚é–“": "",  # ç³»çµ±è‡ªå‹•
                "æ›´æ–°æ™‚é–“": "",  # ç³»çµ±è‡ªå‹•
            }
        ]

        df = pd.DataFrame(template_data)

        # ç”¢ç”Ÿ Excel
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='å…¬æ–‡åŒ¯å…¥')

            # èª¿æ•´æ¬„ä½å¯¬åº¦
            worksheet = writer.sheets['å…¬æ–‡åŒ¯å…¥']
            for idx, col in enumerate(df.columns):
                col_letter = chr(65 + idx) if idx < 26 else f"A{chr(65 + idx - 26)}"
                worksheet.column_dimensions[col_letter].width = 15

        output.seek(0)

        filename_cn = "å…¬æ–‡åŒ¯å…¥ç¯„æœ¬.xlsx"
        filename_encoded = quote(filename_cn)

        return StreamingResponse(
            iter([output.getvalue()]),
            media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            headers={
                "Content-Disposition": f"attachment; filename*=UTF-8''{filename_encoded}"
            }
        )

    except Exception as e:
        logger.error(f"ä¸‹è¼‰ç¯„æœ¬å¤±æ•—: {e}", exc_info=True)
        from fastapi import HTTPException
        raise HTTPException(status_code=500, detail=f"ä¸‹è¼‰ç¯„æœ¬å¤±æ•—: {str(e)}")
