"""
å…¬æ–‡æœå‹™å±¤ - æ¥­å‹™é‚è¼¯è™•ç† (å·²é‡æ§‹)

v2.1 - 2026-01-10
- æ–°å¢è¡Œç´šåˆ¥æ¬Šé™éæ¿¾ (Row-Level Security)
- éç®¡ç†å“¡åªèƒ½æŸ¥çœ‹é—œè¯å°ˆæ¡ˆçš„å…¬æ–‡

è·è²¬ï¼š
- å…¬æ–‡ CRUD æ“ä½œ
- å…¬æ–‡æŸ¥è©¢èˆ‡ç¯©é¸
- å…¬æ–‡åŒ¯å…¥ï¼ˆå§”æ´¾çµ¦ç­–ç•¥é¡åˆ¥ï¼‰

å·²æ‹†åˆ†æ¨¡çµ„ï¼š
- AgencyMatcher: æ©Ÿé—œåç¨±åŒ¹é… (app.services.strategies)
- ProjectMatcher: æ¡ˆä»¶åç¨±åŒ¹é… (app.services.strategies)
- DocumentCalendarIntegrator: æ—¥æ›†æ•´åˆ
"""
import logging
import time
import pandas as pd
from typing import List, Optional, Dict, Any, TYPE_CHECKING
from datetime import datetime, date
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import and_, or_, extract, func, select, exists
from sqlalchemy.exc import IntegrityError

from sqlalchemy.orm import selectinload, joinedload

from app.extended.models import (
    OfficialDocument as Document,
    ContractProject,
    GovernmentAgency,
    project_user_assignment
)

if TYPE_CHECKING:
    from app.extended.models import User

from app.schemas.document import DocumentFilter, DocumentImportResult, DocumentSearchRequest
from app.services.document_calendar_integrator import DocumentCalendarIntegrator
from app.services.strategies.agency_matcher import AgencyMatcher, ProjectMatcher
from app.services.calendar.event_auto_builder import CalendarEventAutoBuilder
from app.core.cache_manager import cache_dropdown_data, cache_statistics

logger = logging.getLogger(__name__)


class DocumentService:
    """
    å…¬æ–‡æœå‹™é¡åˆ¥

    æä¾›å…¬æ–‡ç›¸é—œçš„æ¥­å‹™é‚è¼¯ï¼ŒåŒ…æ‹¬ï¼š
    - CRUD æ“ä½œ
    - æŸ¥è©¢èˆ‡ç¯©é¸
    - åŒ¯å…¥åŒ¯å‡º

    ä½¿ç”¨ç­–ç•¥æ¨¡å¼è™•ç†ï¼š
    - æ©Ÿé—œåç¨±åŒ¹é… (AgencyMatcher)
    - æ¡ˆä»¶åç¨±åŒ¹é… (ProjectMatcher)
    """

    def __init__(self, db: AsyncSession, auto_create_events: bool = True):
        self.db = db
        self.calendar_integrator = DocumentCalendarIntegrator()
        # åˆå§‹åŒ–ç­–ç•¥é¡åˆ¥
        self._agency_matcher = AgencyMatcher(db)
        self._project_matcher = ProjectMatcher(db)
        # è¡Œäº‹æ›†äº‹ä»¶è‡ªå‹•å»ºç«‹å™¨
        self._auto_create_events = auto_create_events
        self._event_builder = CalendarEventAutoBuilder(db) if auto_create_events else None

    async def _get_or_create_agency_id(self, agency_name: Optional[str]) -> Optional[int]:
        """
        æ™ºæ…§æ©Ÿé—œåç¨±åŒ¹é… (å§”æ´¾çµ¦ AgencyMatcher)

        åŒ¹é…ç­–ç•¥ï¼š
        1. ç²¾ç¢ºåŒ¹é… agency_name
        2. ç²¾ç¢ºåŒ¹é… agency_short_name
        3. æ¨¡ç³ŠåŒ¹é…
        4. è‡ªå‹•æ–°å¢

        Args:
            agency_name: æ©Ÿé—œåç¨±

        Returns:
            æ©Ÿé—œ ID
        """
        return await self._agency_matcher.match_or_create(agency_name)

    async def _get_or_create_project_id(self, project_name: Optional[str]) -> Optional[int]:
        """
        æ™ºæ…§æ¡ˆä»¶åç¨±åŒ¹é… (å§”æ´¾çµ¦ ProjectMatcher)

        Args:
            project_name: æ¡ˆä»¶åç¨±

        Returns:
            æ¡ˆä»¶ ID
        """
        return await self._project_matcher.match_or_create(project_name)

    def _parse_date_string(self, date_str: str) -> date:
        """
        è§£ææ—¥æœŸå­—ä¸²ç‚º date ç‰©ä»¶

        æ”¯æ´æ ¼å¼ï¼šYYYY-MM-DD, YYYY/MM/DD

        Args:
            date_str: æ—¥æœŸå­—ä¸²

        Returns:
            date ç‰©ä»¶æˆ– None
        """
        if not date_str:
            return None
        try:
            normalized = date_str.replace('/', '-')
            return datetime.strptime(normalized, '%Y-%m-%d').date()
        except ValueError:
            logger.warning(f"[ç¯©é¸] ç„¡æ•ˆçš„æ—¥æœŸæ ¼å¼: {date_str}")
            return None

    def _extract_agency_names(self, agency_value: str) -> list:
        """
        å¾ä¸‹æ‹‰é¸é …å€¼ä¸­æå–æ©Ÿé—œåç¨±

        æ”¯æ´æ ¼å¼ï¼š
        - ç´”åç¨±: "æ¡ƒåœ’å¸‚æ”¿åºœ"
        - ä»£ç¢¼+åç¨±: "380110000G (æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€)"
        - å¤šæ©Ÿé—œ: "376480000A (å—æŠ•ç¸£æ”¿åºœ) | A01020100G (å…§æ”¿éƒ¨åœ‹åœŸç®¡ç†ç½²åŸé„‰ç™¼å±•åˆ†ç½²)"
        - æ›è¡Œæ ¼å¼: "380110000G\\n(æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€)"

        Args:
            agency_value: ä¸‹æ‹‰é¸é …å€¼

        Returns:
            æå–å‡ºçš„æ©Ÿé—œåç¨±åˆ—è¡¨
        """
        import re

        if not agency_value:
            return []

        names = []

        # å…ˆæŒ‰ | åˆ†å‰²å¤šå€‹æ©Ÿé—œ
        parts = agency_value.split('|')

        for part in parts:
            part = part.strip()
            if not part:
                continue

            # è™•ç†æ›è¡Œæ ¼å¼: "380110000G\n(æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€)"
            part = part.replace('\n', ' ').replace('\r', ' ')

            # å˜—è©¦æå–æ‹¬è™Ÿå…§çš„åç¨±: "380110000G (æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€)" -> "æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€"
            match = re.search(r'\(([^)]+)\)', part)
            if match:
                names.append(match.group(1).strip())
            else:
                # å˜—è©¦ç§»é™¤ä»£ç¢¼å‰ç¶´: "380110000G æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€" -> "æ¡ƒåœ’å¸‚æ”¿åºœå·¥å‹™å±€"
                # ä»£ç¢¼æ ¼å¼é€šå¸¸æ˜¯ å­—æ¯+æ•¸å­— çµ„åˆ
                cleaned = re.sub(r'^[A-Z0-9]+\s*', '', part, flags=re.IGNORECASE)
                if cleaned:
                    names.append(cleaned.strip())
                else:
                    # å¦‚æœå…¨éƒ½è¢«ç§»é™¤äº†ï¼Œå°±ç”¨åŸå€¼ï¼ˆå¯èƒ½æœ¬èº«å°±æ˜¯ç´”åç¨±ï¼‰
                    names.append(part)

        return names

    def _apply_filters(self, query, filters: DocumentFilter):
        """
        å¥—ç”¨ç¯©é¸æ¢ä»¶åˆ°æŸ¥è©¢

        ä½¿ç”¨ DocumentFilter çš„è¼”åŠ©æ–¹æ³•å–å¾—æœ‰æ•ˆå€¼ï¼Œ
        æ”¯æ´å¤šç¨®åƒæ•¸å‘½åæ…£ä¾‹ (å¦‚ date_from å’Œ doc_date_from)

        Args:
            query: SQLAlchemy æŸ¥è©¢ç‰©ä»¶
            filters: ç¯©é¸æ¢ä»¶

        Returns:
            å¥—ç”¨ç¯©é¸å¾Œçš„æŸ¥è©¢ç‰©ä»¶
        """
        # å–å¾—æœ‰æ•ˆçš„ç¯©é¸å€¼ (ä½¿ç”¨ DocumentFilter çš„è¼”åŠ©æ–¹æ³•)
        effective_keyword = filters.get_effective_keyword() if hasattr(filters, 'get_effective_keyword') else (filters.keyword or getattr(filters, 'search', None))
        effective_date_from = filters.get_effective_date_from() if hasattr(filters, 'get_effective_date_from') else (filters.date_from or getattr(filters, 'doc_date_from', None))
        effective_date_to = filters.get_effective_date_to() if hasattr(filters, 'get_effective_date_to') else (filters.date_to or getattr(filters, 'doc_date_to', None))

        # å–å¾— doc_number ç¯©é¸å€¼ï¼ˆå°ˆç”¨å…¬æ–‡å­—è™Ÿæœå°‹ï¼‰
        doc_number_filter = getattr(filters, 'doc_number', None)

        # èª¿è©¦æ—¥èªŒ
        logger.info(f"[ç¯©é¸] æœ‰æ•ˆæ¢ä»¶: keyword={effective_keyword}, doc_number={doc_number_filter}, "
                   f"doc_type={filters.doc_type}, year={filters.year}, "
                   f"sender={filters.sender}, receiver={filters.receiver}, "
                   f"delivery_method={filters.delivery_method}, "
                   f"date_from={effective_date_from}, date_to={effective_date_to}, "
                   f"contract_case={filters.contract_case}, category={filters.category}")

        # å…¬æ–‡é¡å‹ç¯©é¸
        if filters.doc_type:
            query = query.where(Document.doc_type == filters.doc_type)

        # å¹´åº¦ç¯©é¸
        if filters.year:
            query = query.where(extract('year', Document.doc_date) == filters.year)

        # å…¬æ–‡å­—è™Ÿå°ˆç”¨ç¯©é¸ï¼ˆåƒ…æœå°‹ doc_number æ¬„ä½ï¼‰
        if doc_number_filter:
            doc_num_kw = f"%{doc_number_filter}%"
            logger.debug(f"[ç¯©é¸] å¥—ç”¨ doc_number å°ˆç”¨ç¯©é¸: {doc_number_filter}")
            query = query.where(Document.doc_number.ilike(doc_num_kw))

        # é—œéµå­—æœå°‹ï¼ˆä¸»æ—¨ã€èªªæ˜ã€å‚™è¨» - ä¸åŒ…å« doc_numberï¼‰
        if effective_keyword:
            kw = f"%{effective_keyword}%"
            query = query.where(or_(
                Document.subject.ilike(kw),
                Document.content.ilike(kw),
                Document.notes.ilike(kw)
            ))

        # æ”¶ç™¼æ–‡åˆ†é¡ç¯©é¸
        if filters.category:
            logger.debug(f"[ç¯©é¸] å¥—ç”¨ category: {filters.category}")
            query = query.where(Document.category == filters.category)

        # ç™¼æ–‡å½¢å¼ç¯©é¸ (é©—è­‰æœ‰æ•ˆå€¼)
        if filters.delivery_method:
            valid_methods = ['é›»å­äº¤æ›', 'ç´™æœ¬éƒµå¯„']
            if filters.delivery_method in valid_methods:
                logger.debug(f"[ç¯©é¸] å¥—ç”¨ delivery_method: {filters.delivery_method}")
                query = query.where(Document.delivery_method == filters.delivery_method)
            else:
                logger.warning(f"[ç¯©é¸] ç„¡æ•ˆçš„ delivery_method: {filters.delivery_method}")

        # ç™¼æ–‡å–®ä½ç¯©é¸ (æ™ºèƒ½åç¨±æå– + æ¨¡ç³ŠåŒ¹é…)
        if filters.sender:
            sender_names = self._extract_agency_names(filters.sender)
            logger.debug(f"[ç¯©é¸] å¥—ç”¨ sender: {filters.sender} -> æå–åç¨±: {sender_names}")
            if sender_names:
                # ä½¿ç”¨ OR é‚è¼¯åŒ¹é…ä»»ä¸€åç¨±
                sender_conditions = [Document.sender.ilike(f"%{name}%") for name in sender_names]
                query = query.where(or_(*sender_conditions))

        # å—æ–‡å–®ä½ç¯©é¸ (æ™ºèƒ½åç¨±æå– + æ¨¡ç³ŠåŒ¹é…)
        if filters.receiver:
            receiver_names = self._extract_agency_names(filters.receiver)
            logger.debug(f"[ç¯©é¸] å¥—ç”¨ receiver: {filters.receiver} -> æå–åç¨±: {receiver_names}")
            if receiver_names:
                # ä½¿ç”¨ OR é‚è¼¯åŒ¹é…ä»»ä¸€åç¨±
                receiver_conditions = [Document.receiver.ilike(f"%{name}%") for name in receiver_names]
                query = query.where(or_(*receiver_conditions))

        # å…¬æ–‡æ—¥æœŸç¯„åœç¯©é¸
        if effective_date_from:
            date_from_val = self._parse_date_string(effective_date_from) if isinstance(effective_date_from, str) else effective_date_from
            if date_from_val:
                logger.debug(f"[ç¯©é¸] å¥—ç”¨ date_from: {date_from_val}")
                query = query.where(Document.doc_date >= date_from_val)

        if effective_date_to:
            date_to_val = self._parse_date_string(effective_date_to) if isinstance(effective_date_to, str) else effective_date_to
            if date_to_val:
                logger.debug(f"[ç¯©é¸] å¥—ç”¨ date_to: {date_to_val}")
                query = query.where(Document.doc_date <= date_to_val)

        # æ‰¿æ”¬æ¡ˆä»¶ç¯©é¸ (æ¡ˆä»¶åç¨±æˆ–ç·¨è™Ÿæ¨¡ç³ŠåŒ¹é…)
        if filters.contract_case:
            logger.debug(f"[ç¯©é¸] å¥—ç”¨ contract_case: {filters.contract_case}")
            query = query.outerjoin(ContractProject, Document.contract_project_id == ContractProject.id)
            query = query.where(or_(
                ContractProject.project_name.ilike(f"%{filters.contract_case}%"),
                ContractProject.project_code.ilike(f"%{filters.contract_case}%")
            ))

        # æ‰¿è¾¦äººç¯©é¸
        if hasattr(filters, 'assignee') and filters.assignee:
            logger.debug(f"[ç¯©é¸] å¥—ç”¨ assignee: {filters.assignee}")
            query = query.where(Document.assignee.ilike(f"%{filters.assignee}%"))

        return query

    async def get_documents(
        self,
        skip: int = 0,
        limit: int = 100,
        filters: Optional[DocumentFilter] = None,
        include_relations: bool = True,
        current_user: Optional["User"] = None
    ) -> Dict[str, Any]:
        """
        å–å¾—å…¬æ–‡åˆ—è¡¨ï¼ˆå«è¡Œç´šåˆ¥æ¬Šé™éæ¿¾ï¼‰

        æ¬Šé™è¦å‰‡ï¼š
        - superuser/admin: å¯æŸ¥çœ‹æ‰€æœ‰å…¬æ–‡
        - ä¸€èˆ¬ä½¿ç”¨è€…: åªèƒ½æŸ¥çœ‹é—œè¯å°ˆæ¡ˆçš„å…¬æ–‡ï¼Œæˆ–ç„¡å°ˆæ¡ˆé—œè¯çš„å…¬æ–‡

        Args:
            skip: è·³éç­†æ•¸
            limit: å–å¾—ç­†æ•¸
            filters: ç¯©é¸æ¢ä»¶
            include_relations: æ˜¯å¦é è¼‰å…¥é—œè¯è³‡æ–™ (N+1 å„ªåŒ–)
            current_user: ç•¶å‰ä½¿ç”¨è€…ï¼ˆç”¨æ–¼æ¬Šé™éæ¿¾ï¼‰

        Returns:
            åˆ†é çµæœå­—å…¸
        """
        try:
            query = select(Document)

            # N+1 æŸ¥è©¢å„ªåŒ–ï¼šé è¼‰å…¥é—œè¯è³‡æ–™
            if include_relations:
                query = query.options(
                    selectinload(Document.contract_project),
                    selectinload(Document.sender_agency),
                    selectinload(Document.receiver_agency),
                )

            # ================================================================
            # ğŸ”’ è¡Œç´šåˆ¥æ¬Šé™éæ¿¾ (Row-Level Security)
            # ================================================================
            if current_user is not None:
                is_admin = getattr(current_user, 'is_admin', False)
                is_superuser = getattr(current_user, 'is_superuser', False)

                if not is_admin and not is_superuser:
                    user_id = current_user.id
                    logger.info(f"[RLS] ä½¿ç”¨è€… {user_id} åŸ·è¡Œå…¬æ–‡æŸ¥è©¢ï¼ˆéç®¡ç†å“¡ï¼Œå¥—ç”¨è¡Œç´šåˆ¥éæ¿¾ï¼‰")

                    # å–å¾—ä½¿ç”¨è€…é—œè¯çš„å°ˆæ¡ˆ ID å­æŸ¥è©¢
                    user_project_ids = select(
                        project_user_assignment.c.project_id
                    ).where(
                        and_(
                            project_user_assignment.c.user_id == user_id,
                            project_user_assignment.c.status.in_(['active', 'Active', None])
                        )
                    )

                    # å…¬æ–‡éæ¿¾é‚è¼¯ï¼š
                    # 1. ç„¡å°ˆæ¡ˆé—œè¯çš„å…¬æ–‡ï¼ˆå…¬é–‹å…¬æ–‡ï¼‰
                    # 2. ä½¿ç”¨è€…æœ‰é—œè¯çš„å°ˆæ¡ˆçš„å…¬æ–‡
                    query = query.where(
                        or_(
                            Document.contract_project_id.is_(None),  # ç„¡å°ˆæ¡ˆé—œè¯
                            Document.contract_project_id.in_(user_project_ids)  # æœ‰é—œè¯çš„å°ˆæ¡ˆ
                        )
                    )
                else:
                    logger.debug(f"[RLS] ç®¡ç†å“¡ {current_user.id} åŸ·è¡Œå…¬æ–‡æŸ¥è©¢ï¼ˆä¸å¥—ç”¨è¡Œç´šåˆ¥éæ¿¾ï¼‰")

            if filters:
                query = self._apply_filters(query, filters)

            # è¨ˆç®—ç¸½æ•¸
            count_query = select(func.count()).select_from(query.subquery())
            total = (await self.db.execute(count_query)).scalar_one()

            # é è¨­æŒ‰å…¬æ–‡æ—¥æœŸé™å†ªæ’åºï¼ˆæœ€æ–°æ—¥æœŸåœ¨æœ€ä¸Šæ–¹ï¼‰ï¼Œæ—¥æœŸç›¸åŒæ™‚æŒ‰ id é™å†ª
            result = await self.db.execute(
                query.order_by(
                    Document.doc_date.desc().nullslast(),
                    Document.id.desc()
                ).offset(skip).limit(limit)
            )
            documents = result.scalars().all()

            return {
                "items": documents,
                "total": total,
                "page": (skip // limit) + 1 if limit > 0 else 1,
                "limit": limit,
                "total_pages": (total + limit - 1) // limit if limit > 0 else 0
            }
        except Exception as e:
            logger.error(f"get_documents å¤±æ•—: {e}", exc_info=True)
            return {"items": [], "total": 0, "page": 1, "limit": limit, "total_pages": 0}

    async def create_document(self, doc_data: Dict[str, Any], current_user_id: int) -> Optional[Document]:
        try:
            sender_agency_id = await self._get_or_create_agency_id(doc_data.get('sender'))
            receiver_agency_id = await self._get_or_create_agency_id(doc_data.get('receiver'))
            project_id = await self._get_or_create_project_id(doc_data.get('contract_case'))
            doc_payload = {k: v for k, v in doc_data.items() if hasattr(Document, k)}
            doc_payload.update({
                'sender_agency_id': sender_agency_id,
                'receiver_agency_id': receiver_agency_id,
                'contract_project_id': project_id
            })
            new_document = Document(**doc_payload)
            self.db.add(new_document)
            await self.db.commit()
            await self.db.refresh(new_document)
            if new_document.receive_date:
                await self.calendar_integrator.convert_document_to_events(db=self.db, document=new_document, creator_id=current_user_id)
            return new_document
        except Exception as e:
            await self.db.rollback()
            logger.error(f"å»ºç«‹å…¬æ–‡æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}", exc_info=True)
            return None

    async def get_document_by_id(
        self,
        document_id: int,
        include_relations: bool = True
    ) -> Optional[Document]:
        """
        æ ¹æ“š ID å–å¾—å…¬æ–‡

        Args:
            document_id: å…¬æ–‡ ID
            include_relations: æ˜¯å¦é è¼‰å…¥é—œè¯è³‡æ–™

        Returns:
            å…¬æ–‡ç‰©ä»¶
        """
        query = select(Document).where(Document.id == document_id)

        # N+1 å„ªåŒ–ï¼šé è¼‰å…¥é—œè¯è³‡æ–™
        if include_relations:
            query = query.options(
                selectinload(Document.contract_project),
                selectinload(Document.sender_agency),
                selectinload(Document.receiver_agency),
                selectinload(Document.attachments),
            )

        result = await self.db.execute(query)
        return result.scalars().first()

    async def _get_next_auto_serial(self, doc_type: str) -> str:
        """ç”¢ç”Ÿä¸‹ä¸€å€‹æµæ°´è™Ÿ (R0001=æ”¶æ–‡, S0001=ç™¼æ–‡)"""
        prefix = 'R' if doc_type == 'æ”¶æ–‡' else 'S'
        # æŸ¥è©¢ç•¶å‰æœ€å¤§æµæ°´è™Ÿ
        result = await self.db.execute(
            select(func.max(Document.auto_serial)).where(
                Document.auto_serial.like(f'{prefix}%')
            )
        )
        max_serial = result.scalar_one_or_none()
        if max_serial:
            try:
                num = int(max_serial[1:]) + 1
            except (ValueError, IndexError):
                num = 1
        else:
            num = 1
        return f'{prefix}{num:04d}'

    async def import_documents_from_processed_data(self, processed_documents: List[Dict[str, Any]]) -> DocumentImportResult:
        """
        å¾å·²è™•ç†çš„æ–‡ä»¶è³‡æ–™åˆ—è¡¨åŒ¯å…¥è³‡æ–™åº«

        æ­¤æ–¹æ³•ç‚º CSV åŒ¯å…¥æµç¨‹çš„æ ¸å¿ƒï¼Œè² è²¬ï¼š
        1. å»é‡æª¢æŸ¥ - æ ¹æ“šå…¬æ–‡å­—è™Ÿ (doc_number) è·³éå·²å­˜åœ¨çš„è¨˜éŒ„
        2. æ©Ÿé—œé—œè¯ - ä½¿ç”¨ AgencyMatcher æ™ºæ…§åŒ¹é…/å»ºç«‹ç™¼æ–‡å–®ä½å’Œå—æ–‡å–®ä½
        3. æ¡ˆä»¶é—œè¯ - ä½¿ç”¨ ProjectMatcher æ™ºæ…§åŒ¹é…/å»ºç«‹æ‰¿æ”¬æ¡ˆä»¶
        4. æµæ°´è™Ÿç”¢ç”Ÿ - æ ¹æ“šæ–‡ä»¶é¡å‹è‡ªå‹•ç”¢ç”Ÿåºè™Ÿ (R0001/S0001)

        æ©Ÿé—œåŒ¹é…æµç¨‹ï¼ˆAgencyMatcher.match_or_createï¼‰ï¼š
        - æ”¯æ´è§£æ "ä»£ç¢¼ (åç¨±)" æˆ– "ä»£ç¢¼ åç¨±" æ ¼å¼
        - åŒ¹é…é †åºï¼šç²¾ç¢ºåç¨± > è§£æå¾Œåç¨± > ä»£ç¢¼ > ç°¡ç¨± > æ¨¡ç³ŠåŒ¹é… > è‡ªå‹•å»ºç«‹
        - è©³è¦‹ app/services/strategies/agency_matcher.py

        Args:
            processed_documents: å·²ç”± DocumentCSVProcessor è™•ç†çš„æ–‡ä»¶å­—å…¸åˆ—è¡¨

        Returns:
            DocumentImportResult: åŒ¯å…¥çµæœï¼ŒåŒ…å«æˆåŠŸ/å¤±æ•—/è·³éæ•¸é‡åŠéŒ¯èª¤è¨Šæ¯

        ç¶­è­·èªªæ˜ï¼š
        - è‹¥éœ€ä¿®æ”¹æ©Ÿé—œåŒ¹é…é‚è¼¯ï¼Œè«‹ä¿®æ”¹ AgencyMatcher
        - è‹¥éœ€ä¿®æ”¹æ¡ˆä»¶åŒ¹é…é‚è¼¯ï¼Œè«‹ä¿®æ”¹ ProjectMatcher
        - è‹¥éœ€ä¿®å¾©å·²åŒ¯å…¥çš„éŒ¯èª¤æ©Ÿé—œè³‡æ–™ï¼Œä½¿ç”¨ POST /api/agencies/fix-parsed-names
        """
        start_time = time.time()
        total_rows = len(processed_documents)
        success_count = 0
        error_count = 0
        skipped_count = 0
        errors: List[str] = []

        for idx, doc_data in enumerate(processed_documents):
            try:
                doc_number = doc_data.get('doc_number', '').strip()

                # æª¢æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆå»é‡ï¼‰
                if doc_number:
                    existing = await self.db.execute(
                        select(Document).where(Document.doc_number == doc_number)
                    )
                    if existing.scalar_one_or_none():
                        logger.debug(f"è·³éé‡è¤‡å…¬æ–‡: {doc_number}")
                        skipped_count += 1
                        continue

                # æº–å‚™åŒ¯å…¥è³‡æ–™
                sender_agency_id = await self._get_or_create_agency_id(doc_data.get('sender'))
                receiver_agency_id = await self._get_or_create_agency_id(doc_data.get('receiver'))
                project_id = await self._get_or_create_project_id(doc_data.get('contract_case'))

                # å–å¾—æ–‡ä»¶é¡å‹ä¸¦ç”¢ç”Ÿæµæ°´è™Ÿ
                doc_type = doc_data.get('doc_type', 'æ”¶æ–‡')
                auto_serial = await self._get_next_auto_serial(doc_type)

                # æ˜ å°„æ¬„ä½åˆ°è³‡æ–™åº«æ¨¡å‹ (æ³¨æ„ï¼šOfficialDocument æ¨¡å‹æ²’æœ‰ notes æ¬„ä½)
                doc_payload = {
                    'auto_serial': auto_serial,
                    'doc_number': doc_number,
                    'doc_type': doc_type,
                    'category': doc_type,  # category èˆ‡ doc_type ç›¸åŒ
                    'subject': doc_data.get('subject', ''),
                    'sender': doc_data.get('sender', ''),
                    'receiver': doc_data.get('receiver', ''),
                    'sender_agency_id': sender_agency_id,
                    'receiver_agency_id': receiver_agency_id,
                    'contract_project_id': project_id,
                    'status': doc_data.get('status', 'å¾…è™•ç†'),
                }

                # è™•ç†æ—¥æœŸæ¬„ä½
                if doc_data.get('doc_date'):
                    try:
                        doc_payload['doc_date'] = datetime.strptime(doc_data['doc_date'], '%Y-%m-%d').date()
                    except (ValueError, TypeError):
                        doc_payload['doc_date'] = None

                if doc_data.get('receive_date'):
                    try:
                        # å˜—è©¦å¤šç¨®æ—¥æœŸæ ¼å¼
                        receive_str = doc_data['receive_date']
                        for fmt in ['%Y-%m-%d', '%Y-%m-%d %H:%M:%S', '%Y/%m/%d', '%Y/%m/%d %H:%M:%S']:
                            try:
                                doc_payload['receive_date'] = datetime.strptime(receive_str, fmt).date()
                                break
                            except ValueError:
                                continue
                        else:
                            doc_payload['receive_date'] = None
                    except (ValueError, TypeError):
                        doc_payload['receive_date'] = None

                # å»ºç«‹æ–‡ä»¶
                new_document = Document(**doc_payload)
                self.db.add(new_document)
                await self.db.flush()

                # è‡ªå‹•å»ºç«‹è¡Œäº‹æ›†äº‹ä»¶
                if self._auto_create_events and self._event_builder:
                    await self._event_builder.auto_create_event(new_document, skip_if_exists=False)

                success_count += 1
                logger.debug(f"æˆåŠŸåŒ¯å…¥å…¬æ–‡: {doc_number}")

            except IntegrityError as e:
                await self.db.rollback()
                skipped_count += 1
                error_msg = f"å…¬æ–‡é•åç´„æŸ (IntegrityError): doc_number='{doc_data.get('doc_number')}', error={str(e)}"
                errors.append(error_msg)
                logger.warning(error_msg)
            except Exception as e:
                error_count += 1
                error_msg = f"ç¬¬ {idx + 1} ç­†åŒ¯å…¥å¤±æ•—: {str(e)}"
                errors.append(error_msg)
                logger.error(error_msg, exc_info=True)

        # æäº¤æ‰€æœ‰è®Šæ›´
        try:
            await self.db.commit()
        except Exception as e:
            await self.db.rollback()
            logger.error(f"æäº¤åŒ¯å…¥è®Šæ›´å¤±æ•—: {e}", exc_info=True)
            raise

        processing_time = time.time() - start_time
        return DocumentImportResult(
            total_rows=total_rows,
            success_count=success_count,
            error_count=error_count,
            skipped_count=skipped_count,
            errors=errors if errors else [],
            processing_time=processing_time
        )
