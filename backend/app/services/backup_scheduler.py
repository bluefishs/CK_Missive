"""
è³‡æ–™åº«å‚™ä»½æ’ç¨‹å™¨
æä¾›æ¯æ—¥è‡ªå‹•å‚™ä»½èˆ‡ç•°åœ°è‡ªå‹•åŒæ­¥åŠŸèƒ½

ä½¿ç”¨ asyncio å¯¦ç¾ï¼Œèˆ‡å…¶ä»–æ’ç¨‹å™¨ä¿æŒä¸€è‡´

@version 2.0.0
@date 2026-02-24

è®Šæ›´è¨˜éŒ„:
- v2.0.0: å‚™ä»½å¤±æ•—é€šçŸ¥ã€è‡ªå‹•ç•°åœ°åŒæ­¥æ’ç¨‹
- v1.2.0: å¾å‚™ä»½æ—¥èªŒæª”æ¡ˆè¼‰å…¥çµ±è¨ˆæ•¸æ“šï¼Œé¿å…é‡å•Ÿå¾Œæ­¸é›¶
"""

import asyncio
import json
import logging
from datetime import datetime, time, timedelta
from pathlib import Path
from typing import Optional

from app.services.backup import backup_service

logger = logging.getLogger(__name__)


async def _notify_backup_event(
    title: str,
    message: str,
    severity: str = "error",
    data: Optional[dict] = None,
) -> None:
    """ç™¼é€å‚™ä»½ç›¸é—œç³»çµ±é€šçŸ¥ï¼ˆä½¿ç”¨ç¨ç«‹ sessionï¼Œä¸å½±éŸ¿å‚™ä»½æµç¨‹ï¼‰"""
    try:
        from app.db.database import AsyncSessionLocal
        from app.extended.models import SystemNotification

        async with AsyncSessionLocal() as db:
            try:
                notification = SystemNotification(
                    user_id=None,  # å»£æ’­çµ¦æ‰€æœ‰ç®¡ç†å“¡
                    title=title,
                    message=message,
                    notification_type="system",
                    is_read=False,
                    data={"severity": severity, "source_table": "backup", **(data or {})},
                )
                db.add(notification)
                await db.commit()
                logger.info(f"[BACKUP-NOTIFY] {severity.upper()}: {title}")
            except Exception as db_err:
                await db.rollback()
                logger.warning(f"[BACKUP-NOTIFY] é€šçŸ¥å»ºç«‹å¤±æ•—: {db_err}")
    except Exception as e:
        # é€šçŸ¥å¤±æ•—ä¸æ‡‰é˜»æ–·å‚™ä»½æµç¨‹
        logger.warning(f"[BACKUP-NOTIFY] Session å»ºç«‹å¤±æ•—: {e}")


class BackupScheduler:
    """å‚™ä»½æ’ç¨‹å™¨"""

    def __init__(self, backup_hour: int = 2, backup_minute: int = 0) -> None:
        """
        åˆå§‹åŒ–å‚™ä»½æ’ç¨‹å™¨

        Args:
            backup_hour: å‚™ä»½åŸ·è¡Œå°æ™‚ (0-23)ï¼Œé è¨­ 2 é»
            backup_minute: å‚™ä»½åŸ·è¡Œåˆ†é˜ (0-59)ï¼Œé è¨­ 0 åˆ†
        """
        self.backup_hour: int = backup_hour
        self.backup_minute: int = backup_minute
        self.is_running: bool = False
        self._task: Optional[asyncio.Task] = None
        self._sync_task: Optional[asyncio.Task] = None
        self._last_backup_time: Optional[datetime] = None
        self._consecutive_failures: int = 0
        self._backup_stats: dict = self._load_stats_from_logs()

    def _load_stats_from_logs(self) -> dict:
        """
        å¾å‚™ä»½æ—¥èªŒæª”æ¡ˆè¼‰å…¥çµ±è¨ˆæ•¸æ“š

        è®€å– backup_operations.jsonï¼Œè¨ˆç®—æˆåŠŸ/å¤±æ•—æ¬¡æ•¸ï¼Œ
        é¿å…é‡å•Ÿå¾Œçµ±è¨ˆæ•¸æ“šæ­¸é›¶ã€‚
        """
        stats = {
            'total_backups': 0,
            'successful_backups': 0,
            'failed_backups': 0,
            'last_backup_result': None
        }

        try:
            # ä½¿ç”¨èˆ‡ backup_service ç›¸åŒçš„æ—¥èªŒè·¯å¾‘
            log_file = backup_service.backup_log_file
            if log_file.exists():
                with open(log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)

                # çµ±è¨ˆ 'create' æ“ä½œçš„æˆåŠŸ/å¤±æ•—æ¬¡æ•¸
                for log in logs:
                    if log.get('action') == 'create':
                        stats['total_backups'] += 1
                        if log.get('status') == 'success':
                            stats['successful_backups'] += 1
                        else:
                            stats['failed_backups'] += 1

                # å–å¾—æœ€è¿‘çš„å‚™ä»½çµæœ
                create_logs = [l for l in logs if l.get('action') == 'create']
                if create_logs:
                    last_log = create_logs[-1]
                    stats['last_backup_result'] = {
                        'success': last_log.get('status') == 'success',
                        'timestamp': last_log.get('timestamp'),
                        'details': last_log.get('details')
                    }

                # è¨ˆç®—å°¾éƒ¨é€£çºŒå¤±æ•—æ¬¡æ•¸ï¼ˆå¾æœ€è¿‘å¾€å›æ•¸ï¼‰
                consecutive = 0
                for log in reversed(create_logs):
                    if log.get('status') == 'success':
                        break
                    consecutive += 1
                self._consecutive_failures = consecutive

                logger.info(f"å¾æ—¥èªŒè¼‰å…¥å‚™ä»½çµ±è¨ˆ: {stats['total_backups']} æ¬¡ "
                           f"(æˆåŠŸ: {stats['successful_backups']}, å¤±æ•—: {stats['failed_backups']}, "
                           f"é€£çºŒå¤±æ•—: {consecutive})")
        except Exception as e:
            logger.warning(f"è¼‰å…¥å‚™ä»½çµ±è¨ˆå¤±æ•—: {e}")

        return stats

    def _get_next_backup_time(self) -> datetime:
        """è¨ˆç®—ä¸‹æ¬¡å‚™ä»½æ™‚é–“"""
        now = datetime.now()
        backup_time = now.replace(
            hour=self.backup_hour,
            minute=self.backup_minute,
            second=0,
            microsecond=0
        )

        # å¦‚æœä»Šå¤©çš„å‚™ä»½æ™‚é–“å·²éï¼Œå‰‡è¨­å®šç‚ºæ˜å¤©
        if backup_time <= now:
            backup_time += timedelta(days=1)

        return backup_time

    def _get_seconds_until_backup(self) -> float:
        """
        è¨ˆç®—è·é›¢ä¸‹æ¬¡å‚™ä»½çš„ç§’æ•¸

        Returns:
            è·é›¢ä¸‹æ¬¡å‚™ä»½çš„ç§’æ•¸
        """
        next_backup = self._get_next_backup_time()
        delta = next_backup - datetime.now()
        return max(delta.total_seconds(), 0)

    async def _perform_backup(self) -> None:
        """åŸ·è¡Œå‚™ä»½ä»»å‹™"""
        logger.info(f"[{datetime.now()}] é–‹å§‹åŸ·è¡Œæ¯æ—¥è‡ªå‹•å‚™ä»½...")
        self._backup_stats['total_backups'] += 1

        try:
            result = await backup_service.create_backup(
                include_database=True,
                include_attachments=True,
                retention_days=7  # ä¿ç•™ 7 å¤©
            )

            self._last_backup_time = datetime.now()
            self._backup_stats['last_backup_result'] = result

            if result.get("success"):
                self._backup_stats['successful_backups'] += 1
                self._consecutive_failures = 0
                db_info = result.get("database_backup", {})
                att_info = result.get("attachments_backup", {})

                logger.info(
                    f"âœ… æ¯æ—¥å‚™ä»½å®Œæˆ - "
                    f"è³‡æ–™åº«: {db_info.get('filename', 'N/A')} ({db_info.get('size_kb', 0)} KB), "
                    f"é™„ä»¶: {att_info.get('dirname', 'N/A')} ({att_info.get('file_count', 0)} æª”æ¡ˆ)"
                )
            else:
                self._backup_stats['failed_backups'] += 1
                self._consecutive_failures += 1
                errors = result.get("errors", [])
                logger.error(f"âŒ æ¯æ—¥å‚™ä»½å¤±æ•—: {errors}")
                await self._handle_backup_failure("; ".join(errors))

        except Exception as e:
            self._backup_stats['failed_backups'] += 1
            self._consecutive_failures += 1
            self._backup_stats['last_backup_result'] = {"success": False, "error": str(e)}
            logger.exception(f"âŒ æ¯æ—¥å‚™ä»½ç™¼ç”Ÿä¾‹å¤–: {e}")
            await self._handle_backup_failure(str(e))

    async def _handle_backup_failure(self, error_msg: str) -> None:
        """è™•ç†å‚™ä»½å¤±æ•—ï¼šæ ¹æ“šé€£çºŒå¤±æ•—æ¬¡æ•¸ç™¼é€ä¸åŒç­‰ç´šé€šçŸ¥"""
        n = self._consecutive_failures
        if n == 1:
            # é¦–æ¬¡å¤±æ•—ï¼šwarning ç´šåˆ¥
            await _notify_backup_event(
                title="æ¯æ—¥è‡ªå‹•å‚™ä»½å¤±æ•—",
                message=f"å‚™ä»½æ–¼ {datetime.now().strftime('%Y-%m-%d %H:%M')} å¤±æ•—: {error_msg[:200]}",
                severity="warning",
                data={"consecutive_failures": n},
            )
        elif n >= 2:
            # é€£çºŒå¤±æ•—ï¼šcritical ç´šåˆ¥
            await _notify_backup_event(
                title=f"å‚™ä»½é€£çºŒå¤±æ•— {n} æ¬¡ â€” éœ€ç«‹å³è™•ç†",
                message=(
                    f"è‡ªå‹•å‚™ä»½å·²é€£çºŒå¤±æ•— {n} æ¬¡ï¼Œæœ€è¿‘éŒ¯èª¤: {error_msg[:200]}ã€‚"
                    f"è«‹æª¢æŸ¥ Docker æœå‹™èˆ‡ç£ç¢Ÿç©ºé–“ã€‚"
                ),
                severity="critical",
                data={"consecutive_failures": n},
            )

    async def _scheduler_loop(self) -> None:
        """æ’ç¨‹å™¨ä¸»è¿´åœˆ"""
        while self.is_running:
            try:
                # è¨ˆç®—ç­‰å¾…æ™‚é–“
                wait_seconds = self._get_seconds_until_backup()
                next_backup = self._get_next_backup_time()

                logger.info(
                    f"ğŸ“… ä¸‹æ¬¡å‚™ä»½æ™‚é–“: {next_backup.strftime('%Y-%m-%d %H:%M:%S')} "
                    f"(ç´„ {wait_seconds / 3600:.1f} å°æ™‚å¾Œ)"
                )

                # ç­‰å¾…åˆ°å‚™ä»½æ™‚é–“
                await asyncio.sleep(wait_seconds)

                # åŸ·è¡Œå‚™ä»½
                if self.is_running:
                    await self._perform_backup()

            except asyncio.CancelledError:
                logger.info("å‚™ä»½æ’ç¨‹å™¨è¿´åœˆè¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.exception(f"å‚™ä»½æ’ç¨‹å™¨è¿´åœˆç™¼ç”ŸéŒ¯èª¤: {e}")
                # ç™¼ç”ŸéŒ¯èª¤æ™‚ç­‰å¾… 5 åˆ†é˜å¾Œé‡è©¦
                await asyncio.sleep(300)

    # =========================================================================
    # ç•°åœ°è‡ªå‹•åŒæ­¥æ’ç¨‹
    # =========================================================================

    async def _remote_sync_loop(self) -> None:
        """ç•°åœ°åŒæ­¥æ’ç¨‹è¿´åœˆï¼šæ ¹æ“š remote_config.sync_interval_hours è‡ªå‹•åŒæ­¥"""
        # å•Ÿå‹•å¾Œç­‰å¾… 5 åˆ†é˜å†é–‹å§‹ï¼ˆè®“å‚™ä»½æœå‹™å®Œå…¨åˆå§‹åŒ–ï¼‰
        await asyncio.sleep(300)

        while self.is_running:
            try:
                config = backup_service._remote_config
                sync_enabled = config.get("sync_enabled", False)
                remote_path = config.get("remote_path")
                interval_hours = config.get("sync_interval_hours", 24)

                if not sync_enabled or not remote_path:
                    # æœªå•Ÿç”¨æˆ–æœªè¨­å®šè·¯å¾‘ï¼Œæ¯ 10 åˆ†é˜é‡æ–°æª¢æŸ¥
                    await asyncio.sleep(600)
                    continue

                # è¨ˆç®—è·é›¢ä¸Šæ¬¡åŒæ­¥çš„æ™‚é–“
                last_sync = config.get("last_sync_time")
                need_sync = True
                if last_sync:
                    try:
                        last_sync_dt = datetime.fromisoformat(last_sync)
                        elapsed_hours = (datetime.now() - last_sync_dt).total_seconds() / 3600
                        if elapsed_hours < interval_hours:
                            # å°šæœªåˆ°é”åŒæ­¥é–“éš”ï¼Œç­‰å¾…å‰©é¤˜æ™‚é–“
                            wait_seconds = (interval_hours - elapsed_hours) * 3600
                            logger.debug(
                                f"ç•°åœ°åŒæ­¥å°šæœªåˆ°æœŸï¼Œ{elapsed_hours:.1f}/{interval_hours}hï¼Œ"
                                f"ç­‰å¾… {wait_seconds / 3600:.1f}h"
                            )
                            await asyncio.sleep(min(wait_seconds, 3600))  # æœ€å¤šç­‰ 1 å°æ™‚å†æª¢æŸ¥
                            need_sync = False
                    except (ValueError, TypeError):
                        pass  # æ™‚é–“è§£æå¤±æ•—ï¼Œç«‹å³åŒæ­¥

                if need_sync and self.is_running:
                    logger.info("é–‹å§‹è‡ªå‹•ç•°åœ°å‚™ä»½åŒæ­¥...")
                    result = await backup_service.sync_to_remote()
                    if result.get("success"):
                        logger.info(
                            f"âœ… ç•°åœ°åŒæ­¥å®Œæˆ: {result.get('synced_files', 0)} æª”æ¡ˆ, "
                            f"{result.get('total_size_kb', 0)} KB"
                        )
                    else:
                        error = result.get("error", "æœªçŸ¥éŒ¯èª¤")
                        logger.error(f"âŒ ç•°åœ°åŒæ­¥å¤±æ•—: {error}")
                        await _notify_backup_event(
                            title="ç•°åœ°å‚™ä»½åŒæ­¥å¤±æ•—",
                            message=f"è‡ªå‹•åŒæ­¥åˆ° {remote_path} å¤±æ•—: {error[:200]}",
                            severity="warning",
                            data={"remote_path": str(remote_path)},
                        )

                    # åŒæ­¥å®Œæˆå¾Œç­‰å¾…è‡³å°‘ 1 å°æ™‚å†æª¢æŸ¥
                    await asyncio.sleep(3600)

            except asyncio.CancelledError:
                logger.info("ç•°åœ°åŒæ­¥æ’ç¨‹è¿´åœˆè¢«å–æ¶ˆ")
                break
            except Exception as e:
                logger.exception(f"ç•°åœ°åŒæ­¥æ’ç¨‹ç™¼ç”ŸéŒ¯èª¤: {e}")
                await asyncio.sleep(600)  # éŒ¯èª¤å¾Œ 10 åˆ†é˜é‡è©¦

    # =========================================================================
    # å•Ÿå‹• / åœæ­¢ / ç‹€æ…‹
    # =========================================================================

    async def start(self) -> None:
        """å•Ÿå‹•æ’ç¨‹å™¨ï¼ˆå«å‚™ä»½æ’ç¨‹ + ç•°åœ°åŒæ­¥æ’ç¨‹ï¼‰"""
        if self.is_running:
            logger.warning("å‚™ä»½æ’ç¨‹å™¨å·²ç¶“åœ¨é‹è¡Œä¸­")
            return

        self.is_running = True
        self._task = asyncio.create_task(self._scheduler_loop())
        self._sync_task = asyncio.create_task(self._remote_sync_loop())
        next_backup = self._get_next_backup_time()
        logger.info(
            f"âœ… å‚™ä»½æ’ç¨‹å™¨å·²å•Ÿå‹• "
            f"(æ¯æ—¥ {self.backup_hour:02d}:{self.backup_minute:02d} åŸ·è¡Œï¼Œ"
            f"ä¸‹æ¬¡: {next_backup.strftime('%Y-%m-%d %H:%M:%S')}ï¼Œ"
            f"ç•°åœ°åŒæ­¥æ’ç¨‹å·²å•Ÿå‹•)"
        )

    async def stop(self) -> None:
        """åœæ­¢æ’ç¨‹å™¨"""
        if not self.is_running:
            return

        self.is_running = False
        for task in [self._task, self._sync_task]:
            if task:
                task.cancel()
                try:
                    await task
                except asyncio.CancelledError:
                    pass
        self._task = None
        self._sync_task = None

        logger.info("âœ… å‚™ä»½æ’ç¨‹å™¨å·²åœæ­¢")

    def get_status(self) -> dict:
        """å–å¾—æ’ç¨‹å™¨ç‹€æ…‹"""
        # ç•°åœ°åŒæ­¥ç‹€æ…‹
        remote_config = backup_service._remote_config
        remote_sync_info = {
            "enabled": remote_config.get("sync_enabled", False),
            "interval_hours": remote_config.get("sync_interval_hours", 24),
            "last_sync": remote_config.get("last_sync_time"),
            "status": remote_config.get("sync_status", "idle"),
        }

        return {
            "running": self.is_running,
            "backup_time": f"{self.backup_hour:02d}:{self.backup_minute:02d}",
            "next_backup": self._get_next_backup_time().isoformat() if self.is_running else None,
            "last_backup": self._last_backup_time.isoformat() if self._last_backup_time else None,
            "consecutive_failures": self._consecutive_failures,
            "remote_sync": remote_sync_info,
            "stats": self._backup_stats,
        }


# å…¨åŸŸæ’ç¨‹å™¨å¯¦ä¾‹
_backup_scheduler: Optional[BackupScheduler] = None


async def start_backup_scheduler() -> None:
    """å•Ÿå‹•å‚™ä»½æ’ç¨‹å™¨"""
    global _backup_scheduler
    if _backup_scheduler is None:
        _backup_scheduler = BackupScheduler(backup_hour=2, backup_minute=0)
    await _backup_scheduler.start()


async def stop_backup_scheduler() -> None:
    """åœæ­¢å‚™ä»½æ’ç¨‹å™¨"""
    global _backup_scheduler
    if _backup_scheduler is not None:
        await _backup_scheduler.stop()


def get_backup_scheduler() -> Optional[BackupScheduler]:
    """å–å¾—å‚™ä»½æ’ç¨‹å™¨å¯¦ä¾‹"""
    return _backup_scheduler


def get_backup_scheduler_status() -> dict:
    """å–å¾—å‚™ä»½æ’ç¨‹å™¨ç‹€æ…‹"""
    if _backup_scheduler is None:
        return {"running": False, "next_backup": None}
    return _backup_scheduler.get_status()


